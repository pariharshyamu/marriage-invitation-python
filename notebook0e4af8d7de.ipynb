{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77aef4ea",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-20T20:10:54.598079Z",
     "iopub.status.busy": "2025-03-20T20:10:54.597695Z",
     "iopub.status.idle": "2025-03-20T20:17:45.863723Z",
     "shell.execute_reply": "2025-03-20T20:17:45.862763Z"
    },
    "papermill": {
     "duration": 411.274518,
     "end_time": "2025-03-20T20:17:45.868070",
     "exception": false,
     "start_time": "2025-03-20T20:10:54.593552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No TPU detected, falling back to GPU/CPU.\n",
      "Using GPU with 1 device(s)\n",
      "\n",
      "Verifying dataset path: /kaggle/input/fruits/fruits-360_100x100/fruits-360\n",
      "Dataset path exists: /kaggle/input/fruits/fruits-360_100x100/fruits-360\n",
      "Using TPU-optimized batch size: 128\n",
      "\n",
      "Analyzing dataset directory structure...\n",
      "  - LICENSE\n",
      "  - Training/ (contains 165 subdirs, 0 files)\n",
      "  - README.md\n",
      "  - Test/ (contains 164 subdirs, 0 files)\n",
      "\n",
      "Found Training directory: /kaggle/input/fruits/fruits-360_100x100/fruits-360/Training\n",
      "  Contains 165 classes\n",
      "    - Melon Piel de Sapo 1: 738 images\n",
      "    - Dates 1: 490 images\n",
      "    - Apple Crimson Snow 1: 444 images\n",
      "\n",
      "Found Test directory: /kaggle/input/fruits/fruits-360_100x100/fruits-360/Test\n",
      "  Contains 164 classes\n",
      "\n",
      "Preparing datasets...\n",
      "\n",
      "Using Training/Test directory structure\n",
      "Found 165 classes in Training directory\n",
      "Found 82566 training images\n",
      "Warning: Test directory for class Caju seed 1 not found\n",
      "Found 27571 test images\n",
      "Split: 74309 training, 8257 validation, 27571 test images\n",
      "Dataset prepared successfully:\n",
      "Number of classes: 165\n",
      "Steps per epoch: 580\n",
      "Validation steps: 64\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_0.75_96_no_top.h5\n",
      "\u001b[1m5903360/5903360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "\n",
      "Model Architecture Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ cast (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cast</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ Conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">648</span> │ cast[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ bn_Conv1                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │ Conv1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ Conv1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bn_Conv1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ expanded_conv_depthwise   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span> │ Conv1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ expanded_conv_depthwise_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │ expanded_conv_depthwi… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ expanded_conv_depthwise_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ expanded_conv_depthwi… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ expanded_conv_project     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ expanded_conv_depthwi… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ expanded_conv_project_BN  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ expanded_conv_project… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_1_expand (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ expanded_conv_project… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_1_expand_BN         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ block_1_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_1_expand_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_1_expand_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_1_pad               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_1_expand_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_1_depthwise         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">864</span> │ block_1_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_1_depthwise_BN      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ block_1_depthwise[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_1_depthwise_relu    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_1_depthwise_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_1_project (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │ block_1_depthwise_rel… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_1_project_BN        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │ block_1_project[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_2_expand (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,456</span> │ block_1_project_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_2_expand_BN         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │ block_2_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_2_expand_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_2_expand_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_2_depthwise         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │ block_2_expand_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_2_depthwise_BN      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │ block_2_depthwise[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_2_depthwise_relu    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_2_depthwise_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_2_project (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,456</span> │ block_2_depthwise_rel… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_2_project_BN        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │ block_2_project[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_2_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_1_project_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                           │                        │                │ block_2_project_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_3_expand (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,456</span> │ block_2_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_3_expand_BN         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │ block_3_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_3_expand_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_3_expand_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_3_pad               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_3_expand_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_3_depthwise         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │ block_3_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_3_depthwise_BN      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │ block_3_depthwise[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_3_depthwise_relu    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_3_depthwise_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_3_project (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,456</span> │ block_3_depthwise_rel… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_3_project_BN        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │ block_3_project[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_4_expand (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,456</span> │ block_3_project_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_4_expand_BN         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │ block_4_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_4_expand_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_4_expand_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_4_depthwise         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │ block_4_expand_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_4_depthwise_BN      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │ block_4_depthwise[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_4_depthwise_relu    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_4_depthwise_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_4_project (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,456</span> │ block_4_depthwise_rel… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_4_project_BN        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │ block_4_project[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_4_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_3_project_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                           │                        │                │ block_4_project_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_5_expand (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,456</span> │ block_4_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_5_expand_BN         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │ block_5_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_5_expand_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_5_expand_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_5_depthwise         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │ block_5_expand_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_5_depthwise_BN      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │ block_5_depthwise[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_5_depthwise_relu    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_5_depthwise_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_5_project (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,456</span> │ block_5_depthwise_rel… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_5_project_BN        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │ block_5_project[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_5_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_4_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                           │                        │                │ block_5_project_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_6_expand (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,456</span> │ block_5_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_6_expand_BN         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │ block_6_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_6_expand_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_6_expand_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_6_pad               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_6_expand_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_6_depthwise         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │ block_6_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_6_depthwise_BN      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │ block_6_depthwise[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_6_depthwise_relu    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_6_depthwise_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_6_project (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,912</span> │ block_6_depthwise_rel… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_6_project_BN        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ block_6_project[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_7_expand (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">13,824</span> │ block_6_project_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_7_expand_BN         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │ block_7_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_7_expand_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_7_expand_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_7_depthwise         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,592</span> │ block_7_expand_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_7_depthwise_BN      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │ block_7_depthwise[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_7_depthwise_relu    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_7_depthwise_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_7_project (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">13,824</span> │ block_7_depthwise_rel… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_7_project_BN        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ block_7_project[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_7_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_6_project_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                           │                        │                │ block_7_project_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_8_expand (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">13,824</span> │ block_7_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_8_expand_BN         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │ block_8_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_8_expand_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_8_expand_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_8_depthwise         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,592</span> │ block_8_expand_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_8_depthwise_BN      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │ block_8_depthwise[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_8_depthwise_relu    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_8_depthwise_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_8_project (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">13,824</span> │ block_8_depthwise_rel… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_8_project_BN        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ block_8_project[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_8_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_7_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                           │                        │                │ block_8_project_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_9_expand (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">13,824</span> │ block_8_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_9_expand_BN         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │ block_9_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_9_expand_relu       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_9_expand_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_9_depthwise         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,592</span> │ block_9_expand_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_9_depthwise_BN      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │ block_9_depthwise[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_9_depthwise_relu    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_9_depthwise_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_9_project (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">13,824</span> │ block_9_depthwise_rel… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_9_project_BN        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ block_9_project[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_9_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_8_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                           │                        │                │ block_9_project_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_10_expand (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">13,824</span> │ block_9_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_10_expand_BN        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │ block_10_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_10_expand_relu      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_10_expand_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_10_depthwise        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,592</span> │ block_10_expand_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_10_depthwise_BN     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │ block_10_depthwise[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_10_depthwise_relu   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_10_depthwise_BN… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_10_project (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">20,736</span> │ block_10_depthwise_re… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_10_project_BN       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │ block_10_project[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_11_expand (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">432</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">31,104</span> │ block_10_project_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_11_expand_BN        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">432</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,728</span> │ block_11_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_11_expand_relu      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">432</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_11_expand_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_11_depthwise        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">432</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,888</span> │ block_11_expand_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_11_depthwise_BN     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">432</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,728</span> │ block_11_depthwise[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_11_depthwise_relu   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">432</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_11_depthwise_BN… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_11_project (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">31,104</span> │ block_11_depthwise_re… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_11_project_BN       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │ block_11_project[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_11_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_10_project_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                           │                        │                │ block_11_project_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_12_expand (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">432</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">31,104</span> │ block_11_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_12_expand_BN        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">432</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,728</span> │ block_12_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_12_expand_relu      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">432</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_12_expand_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_12_depthwise        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">432</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,888</span> │ block_12_expand_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_12_depthwise_BN     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">432</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,728</span> │ block_12_depthwise[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_12_depthwise_relu   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">432</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_12_depthwise_BN… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_12_project (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">31,104</span> │ block_12_depthwise_re… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_12_project_BN       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │ block_12_project[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_12_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_11_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                           │                        │                │ block_12_project_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_13_expand (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">432</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">31,104</span> │ block_12_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_13_expand_BN        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">432</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,728</span> │ block_13_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_13_expand_relu      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">432</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_13_expand_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_13_pad              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">432</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_13_expand_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_13_depthwise        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">432</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,888</span> │ block_13_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_13_depthwise_BN     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">432</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,728</span> │ block_13_depthwise[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_13_depthwise_relu   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">432</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_13_depthwise_BN… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_13_project (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">51,840</span> │ block_13_depthwise_re… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_13_project_BN       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> │ block_13_project[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_14_expand (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">86,400</span> │ block_13_project_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_14_expand_BN        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,880</span> │ block_14_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_14_expand_relu      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_14_expand_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_14_depthwise        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,480</span> │ block_14_expand_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_14_depthwise_BN     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,880</span> │ block_14_depthwise[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_14_depthwise_relu   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_14_depthwise_BN… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_14_project (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">86,400</span> │ block_14_depthwise_re… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_14_project_BN       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> │ block_14_project[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_14_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_13_project_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                           │                        │                │ block_14_project_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_15_expand (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">86,400</span> │ block_14_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_15_expand_BN        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,880</span> │ block_15_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_15_expand_relu      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_15_expand_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_15_depthwise        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,480</span> │ block_15_expand_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_15_depthwise_BN     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,880</span> │ block_15_depthwise[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_15_depthwise_relu   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_15_depthwise_BN… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_15_project (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">86,400</span> │ block_15_depthwise_re… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_15_project_BN       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> │ block_15_project[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_15_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_14_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                           │                        │                │ block_15_project_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_16_expand (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">86,400</span> │ block_15_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_16_expand_BN        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,880</span> │ block_16_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_16_expand_relu      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_16_expand_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_16_depthwise        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,480</span> │ block_16_expand_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_16_depthwise_BN     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,880</span> │ block_16_depthwise[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_16_depthwise_relu   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_16_depthwise_BN… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_16_project (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">172,800</span> │ block_16_depthwise_re… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_16_project_BN       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> │ block_16_project[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ Conv_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">307,200</span> │ block_16_project_BN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ Conv_1_bn                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120</span> │ Conv_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ out_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Conv_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ gap                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ out_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> │ gap[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ cast_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cast</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">21,285</span> │ cast_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ cast (\u001b[38;5;33mCast\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ Conv1 (\u001b[38;5;33mConv2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m24\u001b[0m)     │            \u001b[38;5;34m648\u001b[0m │ cast[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ bn_Conv1                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m24\u001b[0m)     │             \u001b[38;5;34m96\u001b[0m │ Conv1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ Conv1_relu (\u001b[38;5;33mReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m24\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ bn_Conv1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ expanded_conv_depthwise   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m24\u001b[0m)     │            \u001b[38;5;34m216\u001b[0m │ Conv1_relu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ expanded_conv_depthwise_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m24\u001b[0m)     │             \u001b[38;5;34m96\u001b[0m │ expanded_conv_depthwi… │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ expanded_conv_depthwise_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m24\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ expanded_conv_depthwi… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ expanded_conv_project     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │            \u001b[38;5;34m384\u001b[0m │ expanded_conv_depthwi… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)                  │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ expanded_conv_project_BN  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m64\u001b[0m │ expanded_conv_project… │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_1_expand (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │          \u001b[38;5;34m1,536\u001b[0m │ expanded_conv_project… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_1_expand_BN         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │            \u001b[38;5;34m384\u001b[0m │ block_1_expand[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_1_expand_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ block_1_expand_BN[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_1_pad               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ block_1_expand_relu[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_1_depthwise         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │            \u001b[38;5;34m864\u001b[0m │ block_1_pad[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_1_depthwise_BN      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │            \u001b[38;5;34m384\u001b[0m │ block_1_depthwise[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_1_depthwise_relu    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ block_1_depthwise_BN[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_1_project (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m)     │          \u001b[38;5;34m2,304\u001b[0m │ block_1_depthwise_rel… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_1_project_BN        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m)     │             \u001b[38;5;34m96\u001b[0m │ block_1_project[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_2_expand (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │          \u001b[38;5;34m3,456\u001b[0m │ block_1_project_BN[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_2_expand_BN         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │            \u001b[38;5;34m576\u001b[0m │ block_2_expand[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_2_expand_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ block_2_expand_BN[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_2_depthwise         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │          \u001b[38;5;34m1,296\u001b[0m │ block_2_expand_relu[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_2_depthwise_BN      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │            \u001b[38;5;34m576\u001b[0m │ block_2_depthwise[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_2_depthwise_relu    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ block_2_depthwise_BN[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_2_project (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m)     │          \u001b[38;5;34m3,456\u001b[0m │ block_2_depthwise_rel… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_2_project_BN        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m)     │             \u001b[38;5;34m96\u001b[0m │ block_2_project[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_2_add (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ block_1_project_BN[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                           │                        │                │ block_2_project_BN[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_3_expand (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │          \u001b[38;5;34m3,456\u001b[0m │ block_2_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_3_expand_BN         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │            \u001b[38;5;34m576\u001b[0m │ block_3_expand[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_3_expand_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ block_3_expand_BN[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_3_pad               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ block_3_expand_relu[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_3_depthwise         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │          \u001b[38;5;34m1,296\u001b[0m │ block_3_pad[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_3_depthwise_BN      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │            \u001b[38;5;34m576\u001b[0m │ block_3_depthwise[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_3_depthwise_relu    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ block_3_depthwise_BN[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_3_project (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m24\u001b[0m)     │          \u001b[38;5;34m3,456\u001b[0m │ block_3_depthwise_rel… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_3_project_BN        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m24\u001b[0m)     │             \u001b[38;5;34m96\u001b[0m │ block_3_project[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_4_expand (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │          \u001b[38;5;34m3,456\u001b[0m │ block_3_project_BN[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_4_expand_BN         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │            \u001b[38;5;34m576\u001b[0m │ block_4_expand[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_4_expand_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ block_4_expand_BN[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_4_depthwise         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │          \u001b[38;5;34m1,296\u001b[0m │ block_4_expand_relu[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_4_depthwise_BN      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │            \u001b[38;5;34m576\u001b[0m │ block_4_depthwise[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_4_depthwise_relu    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ block_4_depthwise_BN[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_4_project (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m24\u001b[0m)     │          \u001b[38;5;34m3,456\u001b[0m │ block_4_depthwise_rel… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_4_project_BN        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m24\u001b[0m)     │             \u001b[38;5;34m96\u001b[0m │ block_4_project[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_4_add (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m24\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ block_3_project_BN[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                           │                        │                │ block_4_project_BN[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_5_expand (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │          \u001b[38;5;34m3,456\u001b[0m │ block_4_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_5_expand_BN         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │            \u001b[38;5;34m576\u001b[0m │ block_5_expand[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_5_expand_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ block_5_expand_BN[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_5_depthwise         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │          \u001b[38;5;34m1,296\u001b[0m │ block_5_expand_relu[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_5_depthwise_BN      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │            \u001b[38;5;34m576\u001b[0m │ block_5_depthwise[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_5_depthwise_relu    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ block_5_depthwise_BN[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_5_project (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m24\u001b[0m)     │          \u001b[38;5;34m3,456\u001b[0m │ block_5_depthwise_rel… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_5_project_BN        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m24\u001b[0m)     │             \u001b[38;5;34m96\u001b[0m │ block_5_project[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_5_add (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m24\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ block_4_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                           │                        │                │ block_5_project_BN[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_6_expand (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │          \u001b[38;5;34m3,456\u001b[0m │ block_5_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_6_expand_BN         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │            \u001b[38;5;34m576\u001b[0m │ block_6_expand[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_6_expand_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ block_6_expand_BN[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_6_pad               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m144\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ block_6_expand_relu[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_6_depthwise         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m144\u001b[0m)      │          \u001b[38;5;34m1,296\u001b[0m │ block_6_pad[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_6_depthwise_BN      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m144\u001b[0m)      │            \u001b[38;5;34m576\u001b[0m │ block_6_depthwise[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_6_depthwise_relu    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m144\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ block_6_depthwise_BN[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_6_project (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m48\u001b[0m)       │          \u001b[38;5;34m6,912\u001b[0m │ block_6_depthwise_rel… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_6_project_BN        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m48\u001b[0m)       │            \u001b[38;5;34m192\u001b[0m │ block_6_project[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_7_expand (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m288\u001b[0m)      │         \u001b[38;5;34m13,824\u001b[0m │ block_6_project_BN[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_7_expand_BN         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m288\u001b[0m)      │          \u001b[38;5;34m1,152\u001b[0m │ block_7_expand[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_7_expand_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m288\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ block_7_expand_BN[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_7_depthwise         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m288\u001b[0m)      │          \u001b[38;5;34m2,592\u001b[0m │ block_7_expand_relu[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_7_depthwise_BN      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m288\u001b[0m)      │          \u001b[38;5;34m1,152\u001b[0m │ block_7_depthwise[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_7_depthwise_relu    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m288\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ block_7_depthwise_BN[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_7_project (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m48\u001b[0m)       │         \u001b[38;5;34m13,824\u001b[0m │ block_7_depthwise_rel… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_7_project_BN        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m48\u001b[0m)       │            \u001b[38;5;34m192\u001b[0m │ block_7_project[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_7_add (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m48\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ block_6_project_BN[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                           │                        │                │ block_7_project_BN[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_8_expand (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m288\u001b[0m)      │         \u001b[38;5;34m13,824\u001b[0m │ block_7_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_8_expand_BN         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m288\u001b[0m)      │          \u001b[38;5;34m1,152\u001b[0m │ block_8_expand[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_8_expand_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m288\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ block_8_expand_BN[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_8_depthwise         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m288\u001b[0m)      │          \u001b[38;5;34m2,592\u001b[0m │ block_8_expand_relu[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_8_depthwise_BN      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m288\u001b[0m)      │          \u001b[38;5;34m1,152\u001b[0m │ block_8_depthwise[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_8_depthwise_relu    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m288\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ block_8_depthwise_BN[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_8_project (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m48\u001b[0m)       │         \u001b[38;5;34m13,824\u001b[0m │ block_8_depthwise_rel… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_8_project_BN        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m48\u001b[0m)       │            \u001b[38;5;34m192\u001b[0m │ block_8_project[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_8_add (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m48\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ block_7_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                           │                        │                │ block_8_project_BN[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_9_expand (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m288\u001b[0m)      │         \u001b[38;5;34m13,824\u001b[0m │ block_8_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_9_expand_BN         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m288\u001b[0m)      │          \u001b[38;5;34m1,152\u001b[0m │ block_9_expand[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_9_expand_relu       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m288\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ block_9_expand_BN[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_9_depthwise         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m288\u001b[0m)      │          \u001b[38;5;34m2,592\u001b[0m │ block_9_expand_relu[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_9_depthwise_BN      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m288\u001b[0m)      │          \u001b[38;5;34m1,152\u001b[0m │ block_9_depthwise[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_9_depthwise_relu    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m288\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ block_9_depthwise_BN[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_9_project (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m48\u001b[0m)       │         \u001b[38;5;34m13,824\u001b[0m │ block_9_depthwise_rel… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_9_project_BN        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m48\u001b[0m)       │            \u001b[38;5;34m192\u001b[0m │ block_9_project[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_9_add (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m48\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ block_8_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                           │                        │                │ block_9_project_BN[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_10_expand (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m288\u001b[0m)      │         \u001b[38;5;34m13,824\u001b[0m │ block_9_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_10_expand_BN        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m288\u001b[0m)      │          \u001b[38;5;34m1,152\u001b[0m │ block_10_expand[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_10_expand_relu      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m288\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ block_10_expand_BN[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_10_depthwise        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m288\u001b[0m)      │          \u001b[38;5;34m2,592\u001b[0m │ block_10_expand_relu[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_10_depthwise_BN     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m288\u001b[0m)      │          \u001b[38;5;34m1,152\u001b[0m │ block_10_depthwise[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_10_depthwise_relu   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m288\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ block_10_depthwise_BN… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_10_project (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m72\u001b[0m)       │         \u001b[38;5;34m20,736\u001b[0m │ block_10_depthwise_re… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_10_project_BN       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m72\u001b[0m)       │            \u001b[38;5;34m288\u001b[0m │ block_10_project[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_11_expand (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m432\u001b[0m)      │         \u001b[38;5;34m31,104\u001b[0m │ block_10_project_BN[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_11_expand_BN        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m432\u001b[0m)      │          \u001b[38;5;34m1,728\u001b[0m │ block_11_expand[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_11_expand_relu      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m432\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ block_11_expand_BN[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_11_depthwise        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m432\u001b[0m)      │          \u001b[38;5;34m3,888\u001b[0m │ block_11_expand_relu[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_11_depthwise_BN     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m432\u001b[0m)      │          \u001b[38;5;34m1,728\u001b[0m │ block_11_depthwise[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_11_depthwise_relu   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m432\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ block_11_depthwise_BN… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_11_project (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m72\u001b[0m)       │         \u001b[38;5;34m31,104\u001b[0m │ block_11_depthwise_re… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_11_project_BN       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m72\u001b[0m)       │            \u001b[38;5;34m288\u001b[0m │ block_11_project[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_11_add (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m72\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ block_10_project_BN[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                           │                        │                │ block_11_project_BN[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_12_expand (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m432\u001b[0m)      │         \u001b[38;5;34m31,104\u001b[0m │ block_11_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_12_expand_BN        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m432\u001b[0m)      │          \u001b[38;5;34m1,728\u001b[0m │ block_12_expand[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_12_expand_relu      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m432\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ block_12_expand_BN[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_12_depthwise        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m432\u001b[0m)      │          \u001b[38;5;34m3,888\u001b[0m │ block_12_expand_relu[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_12_depthwise_BN     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m432\u001b[0m)      │          \u001b[38;5;34m1,728\u001b[0m │ block_12_depthwise[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_12_depthwise_relu   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m432\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ block_12_depthwise_BN… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_12_project (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m72\u001b[0m)       │         \u001b[38;5;34m31,104\u001b[0m │ block_12_depthwise_re… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_12_project_BN       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m72\u001b[0m)       │            \u001b[38;5;34m288\u001b[0m │ block_12_project[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_12_add (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m72\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ block_11_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                           │                        │                │ block_12_project_BN[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_13_expand (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m432\u001b[0m)      │         \u001b[38;5;34m31,104\u001b[0m │ block_12_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_13_expand_BN        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m432\u001b[0m)      │          \u001b[38;5;34m1,728\u001b[0m │ block_13_expand[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_13_expand_relu      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m432\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ block_13_expand_BN[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_13_pad              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m432\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ block_13_expand_relu[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_13_depthwise        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m432\u001b[0m)      │          \u001b[38;5;34m3,888\u001b[0m │ block_13_pad[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_13_depthwise_BN     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m432\u001b[0m)      │          \u001b[38;5;34m1,728\u001b[0m │ block_13_depthwise[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_13_depthwise_relu   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m432\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ block_13_depthwise_BN… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_13_project (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m120\u001b[0m)      │         \u001b[38;5;34m51,840\u001b[0m │ block_13_depthwise_re… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_13_project_BN       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m120\u001b[0m)      │            \u001b[38;5;34m480\u001b[0m │ block_13_project[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_14_expand (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m720\u001b[0m)      │         \u001b[38;5;34m86,400\u001b[0m │ block_13_project_BN[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_14_expand_BN        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m720\u001b[0m)      │          \u001b[38;5;34m2,880\u001b[0m │ block_14_expand[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_14_expand_relu      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m720\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ block_14_expand_BN[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_14_depthwise        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m720\u001b[0m)      │          \u001b[38;5;34m6,480\u001b[0m │ block_14_expand_relu[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_14_depthwise_BN     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m720\u001b[0m)      │          \u001b[38;5;34m2,880\u001b[0m │ block_14_depthwise[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_14_depthwise_relu   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m720\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ block_14_depthwise_BN… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_14_project (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m120\u001b[0m)      │         \u001b[38;5;34m86,400\u001b[0m │ block_14_depthwise_re… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_14_project_BN       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m120\u001b[0m)      │            \u001b[38;5;34m480\u001b[0m │ block_14_project[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_14_add (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m120\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ block_13_project_BN[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                           │                        │                │ block_14_project_BN[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_15_expand (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m720\u001b[0m)      │         \u001b[38;5;34m86,400\u001b[0m │ block_14_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_15_expand_BN        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m720\u001b[0m)      │          \u001b[38;5;34m2,880\u001b[0m │ block_15_expand[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_15_expand_relu      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m720\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ block_15_expand_BN[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_15_depthwise        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m720\u001b[0m)      │          \u001b[38;5;34m6,480\u001b[0m │ block_15_expand_relu[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_15_depthwise_BN     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m720\u001b[0m)      │          \u001b[38;5;34m2,880\u001b[0m │ block_15_depthwise[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_15_depthwise_relu   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m720\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ block_15_depthwise_BN… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_15_project (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m120\u001b[0m)      │         \u001b[38;5;34m86,400\u001b[0m │ block_15_depthwise_re… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_15_project_BN       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m120\u001b[0m)      │            \u001b[38;5;34m480\u001b[0m │ block_15_project[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_15_add (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m120\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ block_14_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                           │                        │                │ block_15_project_BN[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_16_expand (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m720\u001b[0m)      │         \u001b[38;5;34m86,400\u001b[0m │ block_15_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_16_expand_BN        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m720\u001b[0m)      │          \u001b[38;5;34m2,880\u001b[0m │ block_16_expand[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_16_expand_relu      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m720\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ block_16_expand_BN[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_16_depthwise        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m720\u001b[0m)      │          \u001b[38;5;34m6,480\u001b[0m │ block_16_expand_relu[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_16_depthwise_BN     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m720\u001b[0m)      │          \u001b[38;5;34m2,880\u001b[0m │ block_16_depthwise[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_16_depthwise_relu   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m720\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ block_16_depthwise_BN… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)                    │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_16_project (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m240\u001b[0m)      │        \u001b[38;5;34m172,800\u001b[0m │ block_16_depthwise_re… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ block_16_project_BN       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m240\u001b[0m)      │            \u001b[38;5;34m960\u001b[0m │ block_16_project[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ Conv_1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │        \u001b[38;5;34m307,200\u001b[0m │ block_16_project_BN[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ Conv_1_bn                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │          \u001b[38;5;34m5,120\u001b[0m │ Conv_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ out_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ Conv_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ gap                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ out_relu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m163,968\u001b[0m │ gap[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ cast_1 (\u001b[38;5;33mCast\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m165\u001b[0m)            │         \u001b[38;5;34m21,285\u001b[0m │ cast_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,567,317</span> (5.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,567,317\u001b[0m (5.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,253</span> (723.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,253\u001b[0m (723.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,382,064</span> (5.27 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,382,064\u001b[0m (5.27 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running a minimal test to check hardware compatibility...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "Hardware compatibility test successful!\n",
      "\n",
      "Starting initial training phase (base model frozen)...\n",
      "Epoch 1/10\n",
      "\u001b[1m580/580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 226ms/step - accuracy: 0.5591 - loss: 2.0269 - top3_acc: 0.6862 - val_accuracy: 0.9769 - val_loss: 0.0541 - val_top3_acc: 0.9843 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m580/580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 36ms/step - accuracy: 0.9541 - loss: 0.1738 - top3_acc: 0.9948 - val_accuracy: 0.9810 - val_loss: 0.0182 - val_top3_acc: 0.9843 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m580/580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - top3_acc: 0.0000e+00 - val_accuracy: 0.9810 - val_loss: 0.0182 - val_top3_acc: 0.9843 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m580/580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 36ms/step - accuracy: 0.9766 - loss: 0.0863 - top3_acc: 0.9989 - val_accuracy: 0.9839 - val_loss: 0.0082 - val_top3_acc: 0.9844 - learning_rate: 9.0000e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m580/580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - top3_acc: 0.0000e+00 - val_accuracy: 0.9839 - val_loss: 0.0082 - val_top3_acc: 0.9844 - learning_rate: 9.0000e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m580/580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 35ms/step - accuracy: 0.9867 - loss: 0.0538 - top3_acc: 0.9990 - val_accuracy: 0.9830 - val_loss: 0.0059 - val_top3_acc: 0.9844 - learning_rate: 9.0000e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m580/580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - top3_acc: 0.0000e+00 - val_accuracy: 0.9830 - val_loss: 0.0059 - val_top3_acc: 0.9844 - learning_rate: 9.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m580/580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 36ms/step - accuracy: 0.9899 - loss: 0.0386 - top3_acc: 0.9997 - val_accuracy: 0.9829 - val_loss: 0.0049 - val_top3_acc: 0.9844 - learning_rate: 8.1000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m580/580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - top3_acc: 0.0000e+00 - val_accuracy: 0.9829 - val_loss: 0.0049 - val_top3_acc: 0.9844 - learning_rate: 8.1000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m580/580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 35ms/step - accuracy: 0.9911 - loss: 0.0328 - top3_acc: 0.9999 - val_accuracy: 0.9839 - val_loss: 0.0030 - val_top3_acc: 0.9844 - learning_rate: 8.1000e-04\n",
      "Initial training phase completed successfully!\n",
      "\n",
      "Starting fine-tuning phase (unfreeze top layers)...\n",
      "Trainable parameters: 764,053\n",
      "Non-trainable parameters: 803,264\n",
      "Epoch 1/5\n",
      "\u001b[1m580/580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 43ms/step - accuracy: 0.6847 - loss: 1.4832 - top3_acc: 0.8460 - val_accuracy: 0.9803 - val_loss: 0.0126 - val_top3_acc: 0.9844 - learning_rate: 1.0000e-05\n",
      "Epoch 2/5\n",
      "\u001b[1m580/580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 40ms/step - accuracy: 0.9330 - loss: 0.2154 - top3_acc: 0.9896 - val_accuracy: 0.9823 - val_loss: 0.0081 - val_top3_acc: 0.9844 - learning_rate: 1.0000e-05\n",
      "Epoch 3/5\n",
      "\u001b[1m580/580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - top3_acc: 0.0000e+00 - val_accuracy: 0.9823 - val_loss: 0.0081 - val_top3_acc: 0.9844 - learning_rate: 1.0000e-05\n",
      "Epoch 4/5\n",
      "\u001b[1m580/580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 40ms/step - accuracy: 0.9636 - loss: 0.1158 - top3_acc: 0.9967 - val_accuracy: 0.9836 - val_loss: 0.0049 - val_top3_acc: 0.9844 - learning_rate: 1.0000e-05\n",
      "Epoch 5/5\n",
      "\u001b[1m580/580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - top3_acc: 0.0000e+00 - val_accuracy: 0.9836 - val_loss: 0.0049 - val_top3_acc: 0.9844 - learning_rate: 1.0000e-05\n",
      "Fine-tuning phase completed successfully!\n",
      "\n",
      "Evaluating model on test dataset...\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 195ms/step - accuracy: 0.9743 - loss: 0.0871 - top3_acc: 0.9968\n",
      "Test loss: 0.1186\n",
      "Test accuracy: 0.9674\n",
      "Test top-3 accuracy: 0.9934\n",
      "\n",
      "Saving model...\n",
      "Saved Keras model to ./mobilenet_fruits360_optimized.keras\n",
      "Saved artifact at '/tmp/tmpg0acgphw'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 165), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  135109025240464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106588432464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106588434928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106588427360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106588430352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106588438624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106588438448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106588439328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106588431584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106588435632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106588146000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106592083104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106592081696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106592089968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106592088912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135110346284672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106592085392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106592093312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106592089088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106592095072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106592088736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591112560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591097248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591102880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591110096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591109216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591104640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591102000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591104464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591102352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591108864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106588547856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106588550848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106588544160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106588552256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106588555952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106588553840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106588546976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106588542048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106588543280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106588555072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106588692320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106588692672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106588703584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106588692848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591109040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590163888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590165120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590169344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590167408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590176736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590173392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590164240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590174096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590176208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590172864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590262544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590263776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590268000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590266064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590274160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590262720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590269936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590264128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590272224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590270816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590361024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590362080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590364192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590361904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590371408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590365952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590367184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590359616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590369472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590367536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485841488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485842544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590375280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485842368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485850112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485846768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485849760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485847472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485849584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485855216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485853808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485745120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485856096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485743184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106590276448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485746880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485748112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485752336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485750400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485757088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485775424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485776304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485757968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485776128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485755856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485780000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485781232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485785456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485783520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485781584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485780176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485787392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485788272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485786688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485788624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485565072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485568064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485568416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485567888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485577568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485572112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485573344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485573520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485575632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485756032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485514336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485515568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485519792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485517856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485525776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485522432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485514688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485523136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485525248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485521904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486168640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486169872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486174096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486172160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486181664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486176208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486177440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486170224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486179728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486178320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486104688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486105744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486107856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486105568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486115072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486109616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486110848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486103280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486113136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486111200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486087424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486088480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486117712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486088304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486096048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486092704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486095696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486093408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486095520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486101152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486099744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485876016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486102032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485874432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108486183952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485876192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485877952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485882176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485880240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485888160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485884816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485877072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485885696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485887104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485884288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591180752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591181984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591186208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591184272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591193776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591188320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591189552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591182336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591191840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591190432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591311296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591314288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591314640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591314112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591323792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591318336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591319568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591319744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591321856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135108485884464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591408896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591409248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591413472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591411536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591420864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591417520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591408368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591418224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591420336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591416992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591506672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591507904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591512128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591510192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591518288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591506848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591514064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591508256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591516352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591521632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591572384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591573440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591522512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591573264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591520400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591577312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591578544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591582768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591580832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591578896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591584880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591672800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591587168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591670864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591587872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591675088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591678080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591678432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591677904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591683536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591682128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591683360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591684416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591785552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591520576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591788192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591789424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591793648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591791712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591799632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591796288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591788544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591797168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591798576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591795760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591852672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591853904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591858128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591856192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591864464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591859008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591860240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591854256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591862528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106591864288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106592178416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106592193200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  135106592185104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Error saving model: Could not translate MLIR to FlatBuffer.<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/Conv1_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/Conv1_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/Conv1_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/Conv1_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/expanded_conv_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.DepthwiseConv2dNative' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/expanded_conv_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/expanded_conv_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/expanded_conv_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/expanded_conv_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/expanded_conv_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_1_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_1_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_1_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_1_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Pad:\", \"functional_1/block_1_pad_1/Pad@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Pad' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Pad:\", \"functional_1/block_1_pad_1/Pad@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_1_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.DepthwiseConv2dNative' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_1_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_1_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_1_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_1_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_1_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_2_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_2_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_2_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_2_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_2_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.DepthwiseConv2dNative' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_2_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_2_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_2_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_2_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_2_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"AddV2:\", \"functional_1/block_2_add_1/Add@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.AddV2' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"AddV2:\", \"functional_1/block_2_add_1/Add@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_3_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_3_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_3_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_3_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Pad:\", \"functional_1/block_3_pad_1/Pad@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Pad' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Pad:\", \"functional_1/block_3_pad_1/Pad@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_3_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.DepthwiseConv2dNative' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_3_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_3_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_3_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_3_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_3_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_4_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_4_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_4_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_4_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_4_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.DepthwiseConv2dNative' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_4_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_4_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_4_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_4_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_4_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"AddV2:\", \"functional_1/block_4_add_1/Add@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.AddV2' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"AddV2:\", \"functional_1/block_4_add_1/Add@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_5_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_5_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_5_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_5_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_5_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.DepthwiseConv2dNative' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_5_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_5_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_5_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_5_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_5_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"AddV2:\", \"functional_1/block_5_add_1/Add@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.AddV2' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"AddV2:\", \"functional_1/block_5_add_1/Add@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_6_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_6_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_6_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_6_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Pad:\", \"functional_1/block_6_pad_1/Pad@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Pad' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Pad:\", \"functional_1/block_6_pad_1/Pad@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_6_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.DepthwiseConv2dNative' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_6_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_6_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_6_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_6_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_6_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_7_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_7_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_7_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_7_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_7_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.DepthwiseConv2dNative' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_7_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_7_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_7_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_7_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_7_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"AddV2:\", \"functional_1/block_7_add_1/Add@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.AddV2' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"AddV2:\", \"functional_1/block_7_add_1/Add@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_8_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_8_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_8_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_8_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_8_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.DepthwiseConv2dNative' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_8_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_8_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_8_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_8_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_8_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"AddV2:\", \"functional_1/block_8_add_1/Add@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.AddV2' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"AddV2:\", \"functional_1/block_8_add_1/Add@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_9_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_9_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_9_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_9_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_9_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.DepthwiseConv2dNative' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_9_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_9_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_9_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_9_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_9_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"AddV2:\", \"functional_1/block_9_add_1/Add@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.AddV2' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"AddV2:\", \"functional_1/block_9_add_1/Add@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_10_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_10_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_10_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_10_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_10_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.DepthwiseConv2dNative' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_10_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_10_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_10_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_10_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_10_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_11_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_11_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_11_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_11_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_11_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.DepthwiseConv2dNative' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_11_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_11_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_11_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_11_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_11_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"AddV2:\", \"functional_1/block_11_add_1/Add@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.AddV2' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"AddV2:\", \"functional_1/block_11_add_1/Add@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_12_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_12_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_12_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_12_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_12_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.DepthwiseConv2dNative' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_12_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_12_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_12_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_12_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_12_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"AddV2:\", \"functional_1/block_12_add_1/Add@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.AddV2' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"AddV2:\", \"functional_1/block_12_add_1/Add@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_13_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_13_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_13_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_13_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Pad:\", \"functional_1/block_13_pad_1/Pad@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Pad' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Pad:\", \"functional_1/block_13_pad_1/Pad@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_13_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.DepthwiseConv2dNative' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_13_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_13_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_13_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_13_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_13_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_14_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_14_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_14_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_14_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_14_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.DepthwiseConv2dNative' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_14_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_14_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_14_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_14_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_14_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"AddV2:\", \"functional_1/block_14_add_1/Add@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.AddV2' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"AddV2:\", \"functional_1/block_14_add_1/Add@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_15_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_15_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_15_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_15_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_15_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.DepthwiseConv2dNative' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_15_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_15_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_15_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_15_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_15_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"AddV2:\", \"functional_1/block_15_add_1/Add@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.AddV2' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"AddV2:\", \"functional_1/block_15_add_1/Add@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_16_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_16_expand_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_16_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_16_expand_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_16_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.DepthwiseConv2dNative' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"DepthwiseConv2dNative:\", \"functional_1/block_16_depthwise_1/depthwise@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_16_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/block_16_depthwise_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_16_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/block_16_project_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/Conv_1_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Conv2D' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Conv2D:\", \"functional_1/Conv_1_1/convolution@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/out_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu6' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu6:\", \"functional_1/out_relu_1/Relu6@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"MatMul:\", \"functional_1/dense_1_1/MatMul@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.MatMul' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"MatMul:\", \"functional_1/dense_1_1/MatMul@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"AddV2:\", \"functional_1/dense_1_1/Add@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.AddV2' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"AddV2:\", \"functional_1/dense_1_1/Add@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: loc(callsite(callsite(fused[\"Relu:\", \"functional_1/dense_1_1/Relu@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.Relu' op is neither a custom op nor a flex op\n",
      "<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n",
      "<unknown>:0: note: loc(callsite(callsite(fused[\"Relu:\", \"functional_1/dense_1_1/Relu@__inference_function_108310\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_109377\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n",
      "<unknown>:0: error: failed while converting: 'main': \n",
      "Some ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select \n",
      "TF Select ops: AddV2, Conv2D, DepthwiseConv2dNative, MatMul, Pad, Relu, Relu6\n",
      "Details:\n",
      "\ttf.AddV2(tensor<?x128xf16>, tensor<128xf16>) -> (tensor<?x128xf16>) : {device = \"\"}\n",
      "\ttf.AddV2(tensor<?x12x12x24xf16>, tensor<?x12x12x24xf16>) -> (tensor<?x12x12x24xf16>) : {device = \"\"}\n",
      "\ttf.AddV2(tensor<?x24x24x24xf16>, tensor<?x24x24x24xf16>) -> (tensor<?x24x24x24xf16>) : {device = \"\"}\n",
      "\ttf.AddV2(tensor<?x3x3x120xf16>, tensor<?x3x3x120xf16>) -> (tensor<?x3x3x120xf16>) : {device = \"\"}\n",
      "\ttf.AddV2(tensor<?x6x6x48xf16>, tensor<?x6x6x48xf16>) -> (tensor<?x6x6x48xf16>) : {device = \"\"}\n",
      "\ttf.AddV2(tensor<?x6x6x72xf16>, tensor<?x6x6x72xf16>) -> (tensor<?x6x6x72xf16>) : {device = \"\"}\n",
      "\ttf.Conv2D(tensor<?x12x12x144xf16>, tensor<1x1x144x24xf16>) -> (tensor<?x12x12x24xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"SAME\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\n",
      "\ttf.Conv2D(tensor<?x12x12x24xf16>, tensor<1x1x24x144xf16>) -> (tensor<?x12x12x144xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"SAME\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\n",
      "\ttf.Conv2D(tensor<?x24x24x144xf16>, tensor<1x1x144x24xf16>) -> (tensor<?x24x24x24xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"SAME\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\n",
      "\ttf.Conv2D(tensor<?x24x24x24xf16>, tensor<1x1x24x144xf16>) -> (tensor<?x24x24x144xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"SAME\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\n",
      "\ttf.Conv2D(tensor<?x24x24x96xf16>, tensor<1x1x96x24xf16>) -> (tensor<?x24x24x24xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"SAME\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\n",
      "\ttf.Conv2D(tensor<?x3x3x120xf16>, tensor<1x1x120x720xf16>) -> (tensor<?x3x3x720xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"SAME\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\n",
      "\ttf.Conv2D(tensor<?x3x3x240xf16>, tensor<1x1x240x1280xf16>) -> (tensor<?x3x3x1280xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"VALID\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\n",
      "\ttf.Conv2D(tensor<?x3x3x432xf16>, tensor<1x1x432x120xf16>) -> (tensor<?x3x3x120xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"SAME\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\n",
      "\ttf.Conv2D(tensor<?x3x3x720xf16>, tensor<1x1x720x120xf16>) -> (tensor<?x3x3x120xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"SAME\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\n",
      "\ttf.Conv2D(tensor<?x3x3x720xf16>, tensor<1x1x720x240xf16>) -> (tensor<?x3x3x240xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"SAME\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\n",
      "\ttf.Conv2D(tensor<?x48x48x16xf16>, tensor<1x1x16x96xf16>) -> (tensor<?x48x48x96xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"SAME\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\n",
      "\ttf.Conv2D(tensor<?x48x48x24xf16>, tensor<1x1x24x16xf16>) -> (tensor<?x48x48x16xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"SAME\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\n",
      "\ttf.Conv2D(tensor<?x6x6x144xf16>, tensor<1x1x144x48xf16>) -> (tensor<?x6x6x48xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"SAME\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\n",
      "\ttf.Conv2D(tensor<?x6x6x288xf16>, tensor<1x1x288x48xf16>) -> (tensor<?x6x6x48xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"SAME\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\n",
      "\ttf.Conv2D(tensor<?x6x6x288xf16>, tensor<1x1x288x72xf16>) -> (tensor<?x6x6x72xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"SAME\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\n",
      "\ttf.Conv2D(tensor<?x6x6x432xf16>, tensor<1x1x432x72xf16>) -> (tensor<?x6x6x72xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"SAME\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\n",
      "\ttf.Conv2D(tensor<?x6x6x48xf16>, tensor<1x1x48x288xf16>) -> (tensor<?x6x6x288xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"SAME\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\n",
      "\ttf.Conv2D(tensor<?x6x6x72xf16>, tensor<1x1x72x432xf16>) -> (tensor<?x6x6x432xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"SAME\", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}\n",
      "\ttf.Conv2D(tensor<?x96x96x3xf16>, tensor<3x3x3x24xf16>) -> (tensor<?x48x48x24xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"SAME\", strides = [1, 2, 2, 1], use_cudnn_on_gpu = true}\n",
      "\ttf.DepthwiseConv2dNative(tensor<?x12x12x144xf16>, tensor<3x3x144x1xf16>) -> (tensor<?x12x12x144xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"SAME\", strides = [1, 1, 1, 1]}\n",
      "\ttf.DepthwiseConv2dNative(tensor<?x13x13x144xf16>, tensor<3x3x144x1xf16>) -> (tensor<?x6x6x144xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"VALID\", strides = [1, 2, 2, 1]}\n",
      "\ttf.DepthwiseConv2dNative(tensor<?x24x24x144xf16>, tensor<3x3x144x1xf16>) -> (tensor<?x24x24x144xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"SAME\", strides = [1, 1, 1, 1]}\n",
      "\ttf.DepthwiseConv2dNative(tensor<?x25x25x144xf16>, tensor<3x3x144x1xf16>) -> (tensor<?x12x12x144xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"VALID\", strides = [1, 2, 2, 1]}\n",
      "\ttf.DepthwiseConv2dNative(tensor<?x3x3x720xf16>, tensor<3x3x720x1xf16>) -> (tensor<?x3x3x720xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"SAME\", strides = [1, 1, 1, 1]}\n",
      "\ttf.DepthwiseConv2dNative(tensor<?x48x48x24xf16>, tensor<3x3x24x1xf16>) -> (tensor<?x48x48x24xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"SAME\", strides = [1, 1, 1, 1]}\n",
      "\ttf.DepthwiseConv2dNative(tensor<?x49x49x96xf16>, tensor<3x3x96x1xf16>) -> (tensor<?x24x24x96xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"VALID\", strides = [1, 2, 2, 1]}\n",
      "\ttf.DepthwiseConv2dNative(tensor<?x6x6x288xf16>, tensor<3x3x288x1xf16>) -> (tensor<?x6x6x288xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"SAME\", strides = [1, 1, 1, 1]}\n",
      "\ttf.DepthwiseConv2dNative(tensor<?x6x6x432xf16>, tensor<3x3x432x1xf16>) -> (tensor<?x6x6x432xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"SAME\", strides = [1, 1, 1, 1]}\n",
      "\ttf.DepthwiseConv2dNative(tensor<?x7x7x432xf16>, tensor<3x3x432x1xf16>) -> (tensor<?x3x3x432xf16>) : {data_format = \"NHWC\", device = \"\", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"VALID\", strides = [1, 2, 2, 1]}\n",
      "\ttf.MatMul(tensor<?x1280xf16>, tensor<128x1280xf16>) -> (tensor<?x128xf16>) : {grad_a = false, grad_b = false, transpose_a = false, transpose_b = true}\n",
      "\ttf.Pad(tensor<?x12x12x144xf16>, tensor<4x2xi32>) -> (tensor<?x13x13x144xf16>) : {device = \"\"}\n",
      "\ttf.Pad(tensor<?x24x24x144xf16>, tensor<4x2xi32>) -> (tensor<?x25x25x144xf16>) : {device = \"\"}\n",
      "\ttf.Pad(tensor<?x48x48x96xf16>, tensor<4x2xi32>) -> (tensor<?x49x49x96xf16>) : {device = \"\"}\n",
      "\ttf.Pad(tensor<?x6x6x432xf16>, tensor<4x2xi32>) -> (tensor<?x7x7x432xf16>) : {device = \"\"}\n",
      "\ttf.Relu(tensor<?x128xf16>) -> (tensor<?x128xf16>) : {device = \"\"}\n",
      "\ttf.Relu6(tensor<?x12x12x144xf16>) -> (tensor<?x12x12x144xf16>) : {device = \"\"}\n",
      "\ttf.Relu6(tensor<?x24x24x144xf16>) -> (tensor<?x24x24x144xf16>) : {device = \"\"}\n",
      "\ttf.Relu6(tensor<?x24x24x96xf16>) -> (tensor<?x24x24x96xf16>) : {device = \"\"}\n",
      "\ttf.Relu6(tensor<?x3x3x1280xf16>) -> (tensor<?x3x3x1280xf16>) : {device = \"\"}\n",
      "\ttf.Relu6(tensor<?x3x3x432xf16>) -> (tensor<?x3x3x432xf16>) : {device = \"\"}\n",
      "\ttf.Relu6(tensor<?x3x3x720xf16>) -> (tensor<?x3x3x720xf16>) : {device = \"\"}\n",
      "\ttf.Relu6(tensor<?x48x48x24xf16>) -> (tensor<?x48x48x24xf16>) : {device = \"\"}\n",
      "\ttf.Relu6(tensor<?x48x48x96xf16>) -> (tensor<?x48x48x96xf16>) : {device = \"\"}\n",
      "\ttf.Relu6(tensor<?x6x6x144xf16>) -> (tensor<?x6x6x144xf16>) : {device = \"\"}\n",
      "\ttf.Relu6(tensor<?x6x6x288xf16>) -> (tensor<?x6x6x288xf16>) : {device = \"\"}\n",
      "\ttf.Relu6(tensor<?x6x6x432xf16>) -> (tensor<?x6x6x432xf16>) : {device = \"\"}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---- 1. TPU Configuration ----\n",
    "try:\n",
    "    # Detect and initialize TPU\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU:', tpu.cluster_spec().as_dict()['worker'])\n",
    "    \n",
    "    # Connect to TPU cluster\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    \n",
    "    # Initialize TPU system\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    \n",
    "    # Create distribution strategy for TPU\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "    \n",
    "    print(\"TPU detected and configured successfully!\")\n",
    "    print(f\"Number of accelerators: {strategy.num_replicas_in_sync}\")\n",
    "    \n",
    "    # Set mixed precision policy for TPU - Changed from bfloat16 to float16\n",
    "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "    print(\"Using mixed precision float16 policy for TPU\")\n",
    "    \n",
    "    # Print TPU device information\n",
    "    print(\"TPU device information:\")\n",
    "    for device in tf.config.list_logical_devices('TPU'):\n",
    "        print(f\" - {device}\")\n",
    "    \n",
    "except ValueError:\n",
    "    print(\"No TPU detected, falling back to GPU/CPU.\")\n",
    "    # Fallback to GPU configuration\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    if physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "        tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "        strategy = tf.distribute.MirroredStrategy()\n",
    "        print(f\"Using GPU with {strategy.num_replicas_in_sync} device(s)\")\n",
    "    else:\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "        print(\"Using CPU\")\n",
    "\n",
    "# ---- 2. Dataset Path and Model Settings ----\n",
    "DATASET_PATH = \"/kaggle/input/fruits/fruits-360_100x100/fruits-360\"\n",
    "MODEL_PATH = \"./mobilenet_fruits360_optimized.keras\"  # Changed to .keras extension\n",
    "CHECKPOINT_PATH = \"./checkpoints/model_checkpoint.keras\"  # Changed to .keras extension\n",
    "IMG_SIZE = 96\n",
    "BATCH_SIZE = 128  # Will be adjusted based on TPU cores\n",
    "\n",
    "# Create checkpoint directory if it doesn't exist\n",
    "os.makedirs(os.path.dirname(CHECKPOINT_PATH), exist_ok=True)\n",
    "\n",
    "# ---- 3. Dataset Path Verification ----\n",
    "print(f\"\\nVerifying dataset path: {DATASET_PATH}\")\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    print(f\"ERROR: Dataset path {DATASET_PATH} does not exist!\")\n",
    "    # Try to find alternative paths\n",
    "    base_dirs = [\"/kaggle/input\", \"/kaggle/input/fruits\"]\n",
    "    found_paths = []\n",
    "    for base in base_dirs:\n",
    "        if os.path.exists(base):\n",
    "            print(f\"Searching in {base} for fruit datasets...\")\n",
    "            for item in os.listdir(base):\n",
    "                full_path = os.path.join(base, item)\n",
    "                if os.path.isdir(full_path) and (\"fruit\" in item.lower() or \"360\" in item):\n",
    "                    found_paths.append(full_path)\n",
    "    \n",
    "    if found_paths:\n",
    "        print(f\"Found potential dataset paths: {found_paths}\")\n",
    "        # Use the first found path as alternative\n",
    "        DATASET_PATH = found_paths[0]\n",
    "        print(f\"Using alternative path: {DATASET_PATH}\")\n",
    "    else:\n",
    "        raise Exception(\"No fruit dataset found! Please verify the dataset is available.\")\n",
    "else:\n",
    "    print(f\"Dataset path exists: {DATASET_PATH}\")\n",
    "\n",
    "# ---- 4. Adjust batch size to be divisible by TPU cores ----\n",
    "# Make batch size divisible by replica count - important for TPU\n",
    "if 'strategy' in locals() and hasattr(strategy, 'num_replicas_in_sync'):\n",
    "    BATCH_SIZE = 128 * strategy.num_replicas_in_sync  # Base batch size per replica = 128\n",
    "    print(f\"Using TPU-optimized batch size: {BATCH_SIZE}\")\n",
    "\n",
    "# ---- 5. Dataset Directory Structure Analysis ----\n",
    "print(\"\\nAnalyzing dataset directory structure...\")\n",
    "try:\n",
    "    contents = os.listdir(DATASET_PATH)\n",
    "    for item in contents[:10]:  # Show first 10 items\n",
    "        item_path = os.path.join(DATASET_PATH, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            subcontents = os.listdir(item_path)\n",
    "            subdir_count = len([i for i in subcontents if os.path.isdir(os.path.join(item_path, i))])\n",
    "            file_count = len([i for i in subcontents if os.path.isfile(os.path.join(item_path, i))])\n",
    "            print(f\"  - {item}/ (contains {subdir_count} subdirs, {file_count} files)\")\n",
    "        else:\n",
    "            print(f\"  - {item}\")\n",
    "    if len(contents) > 10:\n",
    "        print(f\"  ... and {len(contents) - 10} more items\")\n",
    "except Exception as e:\n",
    "    print(f\"Error listing directory: {e}\")\n",
    "\n",
    "# ---- 6. Check for Training/Test directories ----\n",
    "TRAIN_DIR = os.path.join(DATASET_PATH, \"Training\")\n",
    "TEST_DIR = os.path.join(DATASET_PATH, \"Test\")\n",
    "\n",
    "training_dir_exists = os.path.exists(TRAIN_DIR) and os.path.isdir(TRAIN_DIR)\n",
    "test_dir_exists = os.path.exists(TEST_DIR) and os.path.isdir(TEST_DIR)\n",
    "\n",
    "if training_dir_exists:\n",
    "    print(f\"\\nFound Training directory: {TRAIN_DIR}\")\n",
    "    train_classes = os.listdir(TRAIN_DIR)\n",
    "    print(f\"  Contains {len(train_classes)} classes\")\n",
    "    # Sample a few classes\n",
    "    for cls in train_classes[:3]:\n",
    "        cls_path = os.path.join(TRAIN_DIR, cls)\n",
    "        if os.path.isdir(cls_path):\n",
    "            # Look for images with different extensions\n",
    "            image_count = 0\n",
    "            for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n",
    "                image_count += len(glob.glob(os.path.join(cls_path, ext)))\n",
    "            print(f\"    - {cls}: {image_count} images\")\n",
    "else:\n",
    "    print(f\"Training directory not found at {TRAIN_DIR}\")\n",
    "\n",
    "if test_dir_exists:\n",
    "    print(f\"\\nFound Test directory: {TEST_DIR}\")\n",
    "    test_classes = os.listdir(TEST_DIR)\n",
    "    print(f\"  Contains {len(test_classes)} classes\")\n",
    "else:\n",
    "    print(f\"Test directory not found at {TEST_DIR}\")\n",
    "\n",
    "# ---- 7. Dataset Creation Function ----\n",
    "def prepare_datasets():\n",
    "    \"\"\"Prepare training and validation datasets based on directory structure\"\"\"\n",
    "    # Determine which approach to use based on directory structure\n",
    "    if training_dir_exists and test_dir_exists:\n",
    "        print(\"\\nUsing Training/Test directory structure\")\n",
    "        return prepare_training_test_datasets()\n",
    "    else:\n",
    "        print(\"\\nUsing alternative dataset structure detection\")\n",
    "        return prepare_alternative_datasets()\n",
    "\n",
    "def prepare_training_test_datasets():\n",
    "    \"\"\"Prepare datasets using the Training/Test directory structure\"\"\"\n",
    "    # Process training directory\n",
    "    all_train_images = []\n",
    "    all_train_labels = []\n",
    "    class_dirs = [d for d in os.listdir(TRAIN_DIR) if os.path.isdir(os.path.join(TRAIN_DIR, d))]\n",
    "    class_to_idx = {cls_name: i for i, cls_name in enumerate(class_dirs)}\n",
    "    \n",
    "    print(f\"Found {len(class_dirs)} classes in Training directory\")\n",
    "    \n",
    "    # Get training images\n",
    "    for cls_name in class_dirs:\n",
    "        cls_path = os.path.join(TRAIN_DIR, cls_name)\n",
    "        # Look for different image extensions\n",
    "        for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n",
    "            img_list = glob.glob(os.path.join(cls_path, ext))\n",
    "            for img_path in img_list:\n",
    "                all_train_images.append(img_path)\n",
    "                all_train_labels.append(class_to_idx[cls_name])\n",
    "    \n",
    "    print(f\"Found {len(all_train_images)} training images\")\n",
    "    \n",
    "    # Process test directory\n",
    "    all_test_images = []\n",
    "    all_test_labels = []\n",
    "    \n",
    "    # Check that test directory has same classes\n",
    "    for cls_name in class_dirs:\n",
    "        if cls_name not in class_to_idx:\n",
    "            print(f\"Warning: Class {cls_name} in test set not found in training set\")\n",
    "            continue\n",
    "            \n",
    "        cls_path = os.path.join(TEST_DIR, cls_name)\n",
    "        if not os.path.exists(cls_path):\n",
    "            print(f\"Warning: Test directory for class {cls_name} not found\")\n",
    "            continue\n",
    "            \n",
    "        # Look for different image extensions\n",
    "        for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n",
    "            img_list = glob.glob(os.path.join(cls_path, ext))\n",
    "            for img_path in img_list:\n",
    "                all_test_images.append(img_path)\n",
    "                all_test_labels.append(class_to_idx[cls_name])\n",
    "    \n",
    "    print(f\"Found {len(all_test_images)} test images\")\n",
    "    \n",
    "    if not all_train_images or not all_test_images:\n",
    "        raise Exception(\"No images found in Training/Test directories\")\n",
    "        \n",
    "    # Split training data into train and validation\n",
    "    # Use 10% of training data for validation\n",
    "    train_imgs, val_imgs, train_labels, val_labels = train_test_split(\n",
    "        all_train_images, all_train_labels, test_size=0.1, stratify=all_train_labels, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"Split: {len(train_imgs)} training, {len(val_imgs)} validation, {len(all_test_images)} test images\")\n",
    "    \n",
    "    # Create TF datasets\n",
    "    train_ds = create_tpu_dataset(train_imgs, train_labels, len(class_dirs), is_training=True)\n",
    "    val_ds = create_tpu_dataset(val_imgs, val_labels, len(class_dirs), is_training=False)\n",
    "    test_ds = create_tpu_dataset(all_test_images, all_test_labels, len(class_dirs), is_training=False)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds, len(class_dirs), len(train_imgs), len(val_imgs)\n",
    "\n",
    "def prepare_alternative_datasets():\n",
    "    \"\"\"Prepare datasets using an alternative approach when standard structure not found\"\"\"\n",
    "    # Try to find any classes in the main directory\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # First check if classes are directly in main directory\n",
    "    potential_class_dirs = [d for d in os.listdir(DATASET_PATH) if os.path.isdir(os.path.join(DATASET_PATH, d))]\n",
    "    class_dirs = []\n",
    "    \n",
    "    # Verify which directories contain images (actual classes)\n",
    "    for d in potential_class_dirs:\n",
    "        dir_path = os.path.join(DATASET_PATH, d)\n",
    "        has_images = False\n",
    "        for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n",
    "            if glob.glob(os.path.join(dir_path, ext)):\n",
    "                has_images = True\n",
    "                break\n",
    "        if has_images:\n",
    "            class_dirs.append(d)\n",
    "    \n",
    "    if class_dirs:\n",
    "        print(f\"Found {len(class_dirs)} classes in main directory\")\n",
    "        class_to_idx = {cls_name: i for i, cls_name in enumerate(class_dirs)}\n",
    "        \n",
    "        # Collect images from each class\n",
    "        for cls_name in class_dirs:\n",
    "            cls_path = os.path.join(DATASET_PATH, cls_name)\n",
    "            for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n",
    "                img_list = glob.glob(os.path.join(cls_path, ext))\n",
    "                for img_path in img_list:\n",
    "                    all_images.append(img_path)\n",
    "                    all_labels.append(class_to_idx[cls_name])\n",
    "    \n",
    "    # If no classes found, try recursive search\n",
    "    if not all_images:\n",
    "        print(\"No class directories found in main directory, trying recursive search...\")\n",
    "        \n",
    "        # Map of parent directory to count of image files - to identify likely class dirs\n",
    "        dir_to_img_count = {}\n",
    "        \n",
    "        # Search for image files recursively\n",
    "        for root, _, files in os.walk(DATASET_PATH):\n",
    "            img_count = 0\n",
    "            for f in files:\n",
    "                if f.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    img_count += 1\n",
    "            \n",
    "            if img_count > 0:\n",
    "                dir_to_img_count[root] = img_count\n",
    "        \n",
    "        # Sort directories by image count (descending)\n",
    "        sorted_dirs = sorted(dir_to_img_count.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Print directories with most images\n",
    "        print(\"Directories with most images:\")\n",
    "        for dir_path, count in sorted_dirs[:10]:\n",
    "            print(f\"  {dir_path}: {count} images\")\n",
    "        \n",
    "        # Try to infer classes from directories with images\n",
    "        # Strategy: directories at same level with similar image counts are likely classes\n",
    "        potential_class_dirs = []\n",
    "        \n",
    "        # Get parent of first directory with images\n",
    "        if sorted_dirs:\n",
    "            first_dir = sorted_dirs[0][0]\n",
    "            parent_dir = os.path.dirname(first_dir)\n",
    "            \n",
    "            # Check if siblings have images too\n",
    "            sibling_dirs = [d for d, _ in sorted_dirs if os.path.dirname(d) == parent_dir]\n",
    "            \n",
    "            if len(sibling_dirs) > 1:\n",
    "                print(f\"Found {len(sibling_dirs)} potential class directories under {parent_dir}\")\n",
    "                potential_class_dirs = sibling_dirs\n",
    "            else:\n",
    "                # Just use all directories with images as classes\n",
    "                potential_class_dirs = [d for d, c in sorted_dirs if c >= 5]  # At least 5 images\n",
    "        \n",
    "        if potential_class_dirs:\n",
    "            # Use directory names as class names\n",
    "            class_to_idx = {os.path.basename(d): i for i, d in enumerate(potential_class_dirs)}\n",
    "            \n",
    "            # Collect images from each potential class directory\n",
    "            for cls_path in potential_class_dirs:\n",
    "                cls_name = os.path.basename(cls_path)\n",
    "                for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n",
    "                    img_list = glob.glob(os.path.join(cls_path, ext))\n",
    "                    for img_path in img_list:\n",
    "                        all_images.append(img_path)\n",
    "                        all_labels.append(class_to_idx[cls_name])\n",
    "    \n",
    "    # Final check - did we find any images?\n",
    "    if not all_images:\n",
    "        raise Exception(\"No images found in the dataset with any common structure!\")\n",
    "        \n",
    "    print(f\"Total images found: {len(all_images)}\")\n",
    "    print(f\"Total classes found: {len(set(all_labels))}\")\n",
    "    \n",
    "    # Split into train/val/test (80/10/10)\n",
    "    train_imgs, temp_imgs, train_labels, temp_labels = train_test_split(\n",
    "        all_images, all_labels, test_size=0.2, stratify=all_labels, random_state=42\n",
    "    )\n",
    "    \n",
    "    val_imgs, test_imgs, val_labels, test_labels = train_test_split(\n",
    "        temp_imgs, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"Split: {len(train_imgs)} training, {len(val_imgs)} validation, {len(test_imgs)} test images\")\n",
    "    \n",
    "    # Create TF datasets\n",
    "    num_classes = len(set(all_labels))\n",
    "    train_ds = create_tpu_dataset(train_imgs, train_labels, num_classes, is_training=True)\n",
    "    val_ds = create_tpu_dataset(val_imgs, val_labels, num_classes, is_training=False)\n",
    "    test_ds = create_tpu_dataset(test_imgs, test_labels, num_classes, is_training=False)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds, num_classes, len(train_imgs), len(val_imgs)\n",
    "\n",
    "def decode_img(file_path):\n",
    "    \"\"\"Decode an image file to a tensor\"\"\"\n",
    "    img = tf.io.read_file(file_path)\n",
    "    # Detect the image format\n",
    "    img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
    "    img = tf.cast(img, tf.float32) / 255.0  # Normalize to [0,1]\n",
    "    return img\n",
    "\n",
    "def create_tpu_dataset(image_paths, labels, num_classes, is_training=True):\n",
    "    \"\"\"Create a TPU-optimized dataset from file paths and labels\"\"\"\n",
    "    # Convert Python lists to TensorFlow tensors\n",
    "    paths_ds = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "    labels_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    \n",
    "    # Create a dataset of (path, label) pairs\n",
    "    dataset = tf.data.Dataset.zip((paths_ds, labels_ds))\n",
    "    \n",
    "    # Shuffle if training\n",
    "    if is_training:\n",
    "        dataset = dataset.shuffle(buffer_size=min(10000, len(image_paths)))\n",
    "        \n",
    "    # Map function to process each item\n",
    "    def process_path(file_path, label):\n",
    "        img = decode_img(file_path)\n",
    "        \n",
    "        # Data augmentation for training\n",
    "        if is_training:\n",
    "            img = tf.image.random_flip_left_right(img)\n",
    "            img = tf.image.random_brightness(img, 0.2)\n",
    "            img = tf.image.random_contrast(img, 0.8, 1.2)\n",
    "        \n",
    "        # Apply MobileNetV2 preprocessing\n",
    "        img = tf.keras.applications.mobilenet_v2.preprocess_input(img * 255.0)\n",
    "        \n",
    "        # One-hot encode the label\n",
    "        label = tf.one_hot(label, depth=num_classes)\n",
    "        return img, label\n",
    "        \n",
    "    # Apply processing function to each item\n",
    "    dataset = dataset.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    # Batch the data\n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)  # Important for TPU: drop_remainder=True\n",
    "    \n",
    "    # Use caching for better performance\n",
    "    dataset = dataset.cache()\n",
    "    \n",
    "    # Prefetch for better performance\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# ---- 8. Prepare Datasets ----\n",
    "try:\n",
    "    print(\"\\nPreparing datasets...\")\n",
    "    train_ds, val_ds, test_ds, num_classes, train_size, val_size = prepare_datasets()\n",
    "    \n",
    "    # Calculate steps\n",
    "    steps_per_epoch = train_size // BATCH_SIZE\n",
    "    validation_steps = val_size // BATCH_SIZE\n",
    "    \n",
    "    # Ensure at least one step\n",
    "    steps_per_epoch = max(1, steps_per_epoch)\n",
    "    validation_steps = max(1, validation_steps)\n",
    "    \n",
    "    print(f\"Dataset prepared successfully:\")\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "    print(f\"Validation steps: {validation_steps}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error preparing datasets: {e}\")\n",
    "    # Try again with a more aggressive search\n",
    "    try:\n",
    "        print(\"\\nAttempting to find any images in the dataset...\")\n",
    "        all_image_paths = []\n",
    "        for ext in ['jpg', 'jpeg', 'png', 'JPG', 'JPEG', 'PNG']:\n",
    "            found = glob.glob(os.path.join(DATASET_PATH, \"**\", f\"*.{ext}\"), recursive=True)\n",
    "            all_image_paths.extend(found)\n",
    "            print(f\"Found {len(found)} .{ext} files\")\n",
    "        \n",
    "        if not all_image_paths:\n",
    "            raise Exception(\"No image files found in the dataset\")\n",
    "            \n",
    "        print(f\"Total images found: {len(all_image_paths)}\")\n",
    "        print(\"Sample paths:\")\n",
    "        for path in all_image_paths[:5]:\n",
    "            print(f\"  {path}\")\n",
    "            \n",
    "        raise Exception(\"Dataset structure not compatible with automatic detection. Please check paths.\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Final error: {e2}\")\n",
    "        raise\n",
    "\n",
    "# ---- 9. Model Creation ----\n",
    "def create_model():\n",
    "    \"\"\"Create the MobileNetV2 model for fruit classification\"\"\"\n",
    "    # Use smaller input size and alpha parameter for faster inference\n",
    "    base_model = MobileNetV2(\n",
    "        weights=\"imagenet\", \n",
    "        include_top=False, \n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "        alpha=0.75  # Smaller network (75% of filters)\n",
    "    )\n",
    "\n",
    "    # Freeze base model for initial training\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Efficient Model Head\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D(name=\"gap\")(x)\n",
    "    x = Dense(128, activation=\"relu\", name=\"dense_1\")(x)\n",
    "    x = Dropout(0.4, name=\"dropout_1\")(x)\n",
    "    # Force float32 output for TPU compatibility\n",
    "    output_layer = Dense(num_classes, activation=\"softmax\", dtype='float32', name=\"output\")(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output_layer)\n",
    "    \n",
    "    # Learning rate schedule for better convergence\n",
    "    initial_learning_rate = 0.001\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate,\n",
    "        decay_steps=steps_per_epoch*2,\n",
    "        decay_rate=0.9,\n",
    "        staircase=True\n",
    "    )\n",
    "\n",
    "    # Compilation\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\", tf.keras.metrics.TopKCategoricalAccuracy(k=3, name=\"top3_acc\")]\n",
    "    )\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "# Create model inside TPU/GPU strategy scope\n",
    "with strategy.scope():\n",
    "    model, base_model = create_model()\n",
    "\n",
    "# Model summary\n",
    "print(\"\\nModel Architecture Summary:\")\n",
    "model.summary()\n",
    "\n",
    "# ---- 10. Training Callbacks ----\n",
    "callbacks = [\n",
    "    # Save model checkpoints\n",
    "    ModelCheckpoint(\n",
    "        filepath=CHECKPOINT_PATH,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max'\n",
    "    ),\n",
    "    # Early stopping to prevent overfitting\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    # Reduce learning rate when training plateaus\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss', \n",
    "        factor=0.2, \n",
    "        patience=2, \n",
    "        min_lr=1e-6\n",
    "    )\n",
    "]\n",
    "\n",
    "# ---- 11. Initial TPU Compatibility Test ----\n",
    "print(\"\\nRunning a minimal test to check hardware compatibility...\")\n",
    "try:\n",
    "    # Take just one batch and run for one epoch as a test\n",
    "    test_train_ds = train_ds.take(1).repeat(1)\n",
    "    test_val_ds = val_ds.take(1).repeat(1)\n",
    "    \n",
    "    test_history = model.fit(\n",
    "        test_train_ds,\n",
    "        epochs=1,\n",
    "        steps_per_epoch=1,\n",
    "        validation_data=test_val_ds,\n",
    "        validation_steps=1\n",
    "    )\n",
    "    \n",
    "    print(\"Hardware compatibility test successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Hardware test failed: {e}\")\n",
    "    print(\"Trying alternate configuration...\")\n",
    "    \n",
    "    # Try re-initializing with different settings\n",
    "    try:\n",
    "        if 'tpu' in locals():\n",
    "            tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "            \n",
    "        # Recreate model with simpler configuration\n",
    "        with strategy.scope():\n",
    "            model = tf.keras.Sequential([\n",
    "                tf.keras.applications.MobileNetV2(\n",
    "                    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "                    include_top=False,\n",
    "                    weights='imagenet',\n",
    "                    pooling='avg'\n",
    "                ),\n",
    "                tf.keras.layers.Dense(num_classes, activation='softmax', dtype='float32')\n",
    "            ])\n",
    "            \n",
    "            model.compile(\n",
    "                optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "            \n",
    "            # Try test again\n",
    "            test_train_ds = train_ds.take(1).repeat(1)\n",
    "            test_history = model.fit(\n",
    "                test_train_ds,\n",
    "                epochs=1,\n",
    "                steps_per_epoch=1\n",
    "            )\n",
    "            \n",
    "            print(\"Alternate model configuration successful!\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Alternate configuration also failed: {e2}\")\n",
    "        print(\"Falling back to CPU training with smaller batches...\")\n",
    "        \n",
    "        # Reduce batch size for CPU training\n",
    "        global BATCH_SIZE\n",
    "        original_batch_size = BATCH_SIZE\n",
    "        BATCH_SIZE = 32\n",
    "        print(f\"Reduced batch size from {original_batch_size} to {BATCH_SIZE}\")\n",
    "        \n",
    "        # Recreate datasets with smaller batch size\n",
    "        train_ds, val_ds, test_ds, _, _, _ = prepare_datasets()\n",
    "        \n",
    "        # Recreate model\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "        with strategy.scope():\n",
    "            model, base_model = create_model()\n",
    "\n",
    "# ---- 12. Training Phase 1 ----\n",
    "print(\"\\nStarting initial training phase (base model frozen)...\")\n",
    "try:\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=10,  # Start with 10 epochs\n",
    "        validation_data=val_ds,\n",
    "        callbacks=callbacks,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_steps=validation_steps\n",
    "    )\n",
    "    \n",
    "    print(\"Initial training phase completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during initial training: {e}\")\n",
    "    # Try again with simpler approach\n",
    "    try:\n",
    "        print(\"Attempting simplified training...\")\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            epochs=5,\n",
    "            validation_data=val_ds,\n",
    "            callbacks=[],  # No callbacks to simplify\n",
    "            steps_per_epoch=min(steps_per_epoch, 10),  # Limit steps\n",
    "            validation_steps=min(validation_steps, 5)   # Limit validation steps\n",
    "        )\n",
    "    except Exception as e2:\n",
    "        print(f\"Simplified training also failed: {e2}\")\n",
    "        raise Exception(\"Training failed. Please check hardware and dataset.\")\n",
    "\n",
    "# ---- 13. Fine-tuning Phase ----\n",
    "print(\"\\nStarting fine-tuning phase (unfreeze top layers)...\")\n",
    "try:\n",
    "    # Unfreeze the base model (partially)\n",
    "    with strategy.scope():\n",
    "        # Unfreeze the last block of the MobileNetV2 model\n",
    "        for layer in base_model.layers[-12:]:\n",
    "            layer.trainable = True\n",
    "\n",
    "        # Count trainable parameters\n",
    "        trainable_count = sum(tf.keras.backend.count_params(w) for w in model.trainable_weights)\n",
    "        non_trainable_count = sum(tf.keras.backend.count_params(w) for w in model.non_trainable_weights)\n",
    "        print(f\"Trainable parameters: {trainable_count:,}\")\n",
    "        print(f\"Non-trainable parameters: {non_trainable_count:,}\")\n",
    "\n",
    "        # Use a much smaller learning rate for fine-tuning\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\", tf.keras.metrics.TopKCategoricalAccuracy(k=3, name=\"top3_acc\")]\n",
    "        )\n",
    "\n",
    "    # Fine-tune\n",
    "    history_finetune = model.fit(\n",
    "        train_ds,\n",
    "        epochs=5,\n",
    "        validation_data=val_ds,\n",
    "        callbacks=callbacks,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_steps=validation_steps\n",
    "    )\n",
    "    \n",
    "    print(\"Fine-tuning phase completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during fine-tuning: {e}\")\n",
    "    print(\"Skipping fine-tuning phase.\")\n",
    "    history_finetune = None\n",
    "\n",
    "# ---- 14. Evaluation ----\n",
    "print(\"\\nEvaluating model on test dataset...\")\n",
    "try:\n",
    "    test_results = model.evaluate(test_ds)\n",
    "    print(f\"Test loss: {test_results[0]:.4f}\")\n",
    "    print(f\"Test accuracy: {test_results[1]:.4f}\")\n",
    "    if len(test_results) > 2:\n",
    "        print(f\"Test top-3 accuracy: {test_results[2]:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during evaluation: {e}\")\n",
    "\n",
    "# ---- 15. Save Model ----\n",
    "print(\"\\nSaving model...\")\n",
    "try:\n",
    "    model.save(MODEL_PATH)\n",
    "    print(f\"Saved Keras model to {MODEL_PATH}\")\n",
    "\n",
    "    # Convert to TensorFlow Lite for deployment\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    # Save the TF Lite model\n",
    "    tflite_path = os.path.join(os.path.dirname(MODEL_PATH), 'model.tflite')\n",
    "    with open(tflite_path, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    print(f\"Saved TFLite model to {tflite_path}\")\n",
    "    \n",
    "    # Save class indices for inference\n",
    "    class_indices = {}\n",
    "    if 'class_to_idx' in locals():\n",
    "        class_indices = {cls: idx for cls, idx in class_to_idx.items()}\n",
    "    \n",
    "    # Save to file\n",
    "    import json\n",
    "    with open('class_indices.json', 'w') as f:\n",
    "        json.dump(class_indices, f)\n",
    "    print(\"Saved class indices to class_indices.json\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error saving model: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5857,
     "isSourceIdPinned": false,
     "sourceId": 11105481,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 422.023885,
   "end_time": "2025-03-20T20:17:53.901783",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-20T20:10:51.877898",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
