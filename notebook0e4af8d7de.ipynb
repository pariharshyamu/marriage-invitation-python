{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11105481,"sourceType":"datasetVersion","datasetId":5857,"isSourceIdPinned":false}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nimport os\nimport numpy as np\nimport glob\nfrom sklearn.model_selection import train_test_split\n\n# ---- 1. TPU Configuration ----\ntry:\n    # Detect and initialize TPU\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU:', tpu.cluster_spec().as_dict()['worker'])\n    \n    # Connect to TPU cluster\n    tf.config.experimental_connect_to_cluster(tpu)\n    \n    # Initialize TPU system\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    \n    # Create distribution strategy for TPU\n    strategy = tf.distribute.TPUStrategy(tpu)\n    \n    print(\"TPU detected and configured successfully!\")\n    print(f\"Number of accelerators: {strategy.num_replicas_in_sync}\")\n    \n    # Set mixed precision policy for TPU - Changed from bfloat16 to float16\n    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n    print(\"Using mixed precision float16 policy for TPU\")\n    \n    # Print TPU device information\n    print(\"TPU device information:\")\n    for device in tf.config.list_logical_devices('TPU'):\n        print(f\" - {device}\")\n    \nexcept ValueError:\n    print(\"No TPU detected, falling back to GPU/CPU.\")\n    # Fallback to GPU configuration\n    physical_devices = tf.config.list_physical_devices('GPU')\n    if physical_devices:\n        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n        tf.keras.mixed_precision.set_global_policy('mixed_float16')\n        strategy = tf.distribute.MirroredStrategy()\n        print(f\"Using GPU with {strategy.num_replicas_in_sync} device(s)\")\n    else:\n        strategy = tf.distribute.get_strategy()\n        print(\"Using CPU\")\n\n# ---- 2. Dataset Path and Model Settings ----\nDATASET_PATH = \"/kaggle/input/fruits/fruits-360_100x100/fruits-360\"\nMODEL_PATH = \"./mobilenet_fruits360_optimized.keras\"  # Changed to .keras extension\nCHECKPOINT_PATH = \"./checkpoints/model_checkpoint.keras\"  # Changed to .keras extension\nIMG_SIZE = 96\nBATCH_SIZE = 128  # Will be adjusted based on TPU cores\n\n# Create checkpoint directory if it doesn't exist\nos.makedirs(os.path.dirname(CHECKPOINT_PATH), exist_ok=True)\n\n# ---- 3. Dataset Path Verification ----\nprint(f\"\\nVerifying dataset path: {DATASET_PATH}\")\nif not os.path.exists(DATASET_PATH):\n    print(f\"ERROR: Dataset path {DATASET_PATH} does not exist!\")\n    # Try to find alternative paths\n    base_dirs = [\"/kaggle/input\", \"/kaggle/input/fruits\"]\n    found_paths = []\n    for base in base_dirs:\n        if os.path.exists(base):\n            print(f\"Searching in {base} for fruit datasets...\")\n            for item in os.listdir(base):\n                full_path = os.path.join(base, item)\n                if os.path.isdir(full_path) and (\"fruit\" in item.lower() or \"360\" in item):\n                    found_paths.append(full_path)\n    \n    if found_paths:\n        print(f\"Found potential dataset paths: {found_paths}\")\n        # Use the first found path as alternative\n        DATASET_PATH = found_paths[0]\n        print(f\"Using alternative path: {DATASET_PATH}\")\n    else:\n        raise Exception(\"No fruit dataset found! Please verify the dataset is available.\")\nelse:\n    print(f\"Dataset path exists: {DATASET_PATH}\")\n\n# ---- 4. Adjust batch size to be divisible by TPU cores ----\n# Make batch size divisible by replica count - important for TPU\nif 'strategy' in locals() and hasattr(strategy, 'num_replicas_in_sync'):\n    BATCH_SIZE = 128 * strategy.num_replicas_in_sync  # Base batch size per replica = 128\n    print(f\"Using TPU-optimized batch size: {BATCH_SIZE}\")\n\n# ---- 5. Dataset Directory Structure Analysis ----\nprint(\"\\nAnalyzing dataset directory structure...\")\ntry:\n    contents = os.listdir(DATASET_PATH)\n    for item in contents[:10]:  # Show first 10 items\n        item_path = os.path.join(DATASET_PATH, item)\n        if os.path.isdir(item_path):\n            subcontents = os.listdir(item_path)\n            subdir_count = len([i for i in subcontents if os.path.isdir(os.path.join(item_path, i))])\n            file_count = len([i for i in subcontents if os.path.isfile(os.path.join(item_path, i))])\n            print(f\"  - {item}/ (contains {subdir_count} subdirs, {file_count} files)\")\n        else:\n            print(f\"  - {item}\")\n    if len(contents) > 10:\n        print(f\"  ... and {len(contents) - 10} more items\")\nexcept Exception as e:\n    print(f\"Error listing directory: {e}\")\n\n# ---- 6. Check for Training/Test directories ----\nTRAIN_DIR = os.path.join(DATASET_PATH, \"Training\")\nTEST_DIR = os.path.join(DATASET_PATH, \"Test\")\n\ntraining_dir_exists = os.path.exists(TRAIN_DIR) and os.path.isdir(TRAIN_DIR)\ntest_dir_exists = os.path.exists(TEST_DIR) and os.path.isdir(TEST_DIR)\n\nif training_dir_exists:\n    print(f\"\\nFound Training directory: {TRAIN_DIR}\")\n    train_classes = os.listdir(TRAIN_DIR)\n    print(f\"  Contains {len(train_classes)} classes\")\n    # Sample a few classes\n    for cls in train_classes[:3]:\n        cls_path = os.path.join(TRAIN_DIR, cls)\n        if os.path.isdir(cls_path):\n            # Look for images with different extensions\n            image_count = 0\n            for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n                image_count += len(glob.glob(os.path.join(cls_path, ext)))\n            print(f\"    - {cls}: {image_count} images\")\nelse:\n    print(f\"Training directory not found at {TRAIN_DIR}\")\n\nif test_dir_exists:\n    print(f\"\\nFound Test directory: {TEST_DIR}\")\n    test_classes = os.listdir(TEST_DIR)\n    print(f\"  Contains {len(test_classes)} classes\")\nelse:\n    print(f\"Test directory not found at {TEST_DIR}\")\n\n# ---- 7. Dataset Creation Function ----\ndef prepare_datasets():\n    \"\"\"Prepare training and validation datasets based on directory structure\"\"\"\n    # Determine which approach to use based on directory structure\n    if training_dir_exists and test_dir_exists:\n        print(\"\\nUsing Training/Test directory structure\")\n        return prepare_training_test_datasets()\n    else:\n        print(\"\\nUsing alternative dataset structure detection\")\n        return prepare_alternative_datasets()\n\ndef prepare_training_test_datasets():\n    \"\"\"Prepare datasets using the Training/Test directory structure\"\"\"\n    # Process training directory\n    all_train_images = []\n    all_train_labels = []\n    class_dirs = [d for d in os.listdir(TRAIN_DIR) if os.path.isdir(os.path.join(TRAIN_DIR, d))]\n    class_to_idx = {cls_name: i for i, cls_name in enumerate(class_dirs)}\n    \n    print(f\"Found {len(class_dirs)} classes in Training directory\")\n    \n    # Get training images\n    for cls_name in class_dirs:\n        cls_path = os.path.join(TRAIN_DIR, cls_name)\n        # Look for different image extensions\n        for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n            img_list = glob.glob(os.path.join(cls_path, ext))\n            for img_path in img_list:\n                all_train_images.append(img_path)\n                all_train_labels.append(class_to_idx[cls_name])\n    \n    print(f\"Found {len(all_train_images)} training images\")\n    \n    # Process test directory\n    all_test_images = []\n    all_test_labels = []\n    \n    # Check that test directory has same classes\n    for cls_name in class_dirs:\n        if cls_name not in class_to_idx:\n            print(f\"Warning: Class {cls_name} in test set not found in training set\")\n            continue\n            \n        cls_path = os.path.join(TEST_DIR, cls_name)\n        if not os.path.exists(cls_path):\n            print(f\"Warning: Test directory for class {cls_name} not found\")\n            continue\n            \n        # Look for different image extensions\n        for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n            img_list = glob.glob(os.path.join(cls_path, ext))\n            for img_path in img_list:\n                all_test_images.append(img_path)\n                all_test_labels.append(class_to_idx[cls_name])\n    \n    print(f\"Found {len(all_test_images)} test images\")\n    \n    if not all_train_images or not all_test_images:\n        raise Exception(\"No images found in Training/Test directories\")\n        \n    # Split training data into train and validation\n    # Use 10% of training data for validation\n    train_imgs, val_imgs, train_labels, val_labels = train_test_split(\n        all_train_images, all_train_labels, test_size=0.1, stratify=all_train_labels, random_state=42\n    )\n    \n    print(f\"Split: {len(train_imgs)} training, {len(val_imgs)} validation, {len(all_test_images)} test images\")\n    \n    # Create TF datasets\n    train_ds = create_tpu_dataset(train_imgs, train_labels, len(class_dirs), is_training=True)\n    val_ds = create_tpu_dataset(val_imgs, val_labels, len(class_dirs), is_training=False)\n    test_ds = create_tpu_dataset(all_test_images, all_test_labels, len(class_dirs), is_training=False)\n    \n    return train_ds, val_ds, test_ds, len(class_dirs), len(train_imgs), len(val_imgs)\n\ndef prepare_alternative_datasets():\n    \"\"\"Prepare datasets using an alternative approach when standard structure not found\"\"\"\n    # Try to find any classes in the main directory\n    all_images = []\n    all_labels = []\n    \n    # First check if classes are directly in main directory\n    potential_class_dirs = [d for d in os.listdir(DATASET_PATH) if os.path.isdir(os.path.join(DATASET_PATH, d))]\n    class_dirs = []\n    \n    # Verify which directories contain images (actual classes)\n    for d in potential_class_dirs:\n        dir_path = os.path.join(DATASET_PATH, d)\n        has_images = False\n        for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n            if glob.glob(os.path.join(dir_path, ext)):\n                has_images = True\n                break\n        if has_images:\n            class_dirs.append(d)\n    \n    if class_dirs:\n        print(f\"Found {len(class_dirs)} classes in main directory\")\n        class_to_idx = {cls_name: i for i, cls_name in enumerate(class_dirs)}\n        \n        # Collect images from each class\n        for cls_name in class_dirs:\n            cls_path = os.path.join(DATASET_PATH, cls_name)\n            for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n                img_list = glob.glob(os.path.join(cls_path, ext))\n                for img_path in img_list:\n                    all_images.append(img_path)\n                    all_labels.append(class_to_idx[cls_name])\n    \n    # If no classes found, try recursive search\n    if not all_images:\n        print(\"No class directories found in main directory, trying recursive search...\")\n        \n        # Map of parent directory to count of image files - to identify likely class dirs\n        dir_to_img_count = {}\n        \n        # Search for image files recursively\n        for root, _, files in os.walk(DATASET_PATH):\n            img_count = 0\n            for f in files:\n                if f.lower().endswith(('.jpg', '.jpeg', '.png')):\n                    img_count += 1\n            \n            if img_count > 0:\n                dir_to_img_count[root] = img_count\n        \n        # Sort directories by image count (descending)\n        sorted_dirs = sorted(dir_to_img_count.items(), key=lambda x: x[1], reverse=True)\n        \n        # Print directories with most images\n        print(\"Directories with most images:\")\n        for dir_path, count in sorted_dirs[:10]:\n            print(f\"  {dir_path}: {count} images\")\n        \n        # Try to infer classes from directories with images\n        # Strategy: directories at same level with similar image counts are likely classes\n        potential_class_dirs = []\n        \n        # Get parent of first directory with images\n        if sorted_dirs:\n            first_dir = sorted_dirs[0][0]\n            parent_dir = os.path.dirname(first_dir)\n            \n            # Check if siblings have images too\n            sibling_dirs = [d for d, _ in sorted_dirs if os.path.dirname(d) == parent_dir]\n            \n            if len(sibling_dirs) > 1:\n                print(f\"Found {len(sibling_dirs)} potential class directories under {parent_dir}\")\n                potential_class_dirs = sibling_dirs\n            else:\n                # Just use all directories with images as classes\n                potential_class_dirs = [d for d, c in sorted_dirs if c >= 5]  # At least 5 images\n        \n        if potential_class_dirs:\n            # Use directory names as class names\n            class_to_idx = {os.path.basename(d): i for i, d in enumerate(potential_class_dirs)}\n            \n            # Collect images from each potential class directory\n            for cls_path in potential_class_dirs:\n                cls_name = os.path.basename(cls_path)\n                for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n                    img_list = glob.glob(os.path.join(cls_path, ext))\n                    for img_path in img_list:\n                        all_images.append(img_path)\n                        all_labels.append(class_to_idx[cls_name])\n    \n    # Final check - did we find any images?\n    if not all_images:\n        raise Exception(\"No images found in the dataset with any common structure!\")\n        \n    print(f\"Total images found: {len(all_images)}\")\n    print(f\"Total classes found: {len(set(all_labels))}\")\n    \n    # Split into train/val/test (80/10/10)\n    train_imgs, temp_imgs, train_labels, temp_labels = train_test_split(\n        all_images, all_labels, test_size=0.2, stratify=all_labels, random_state=42\n    )\n    \n    val_imgs, test_imgs, val_labels, test_labels = train_test_split(\n        temp_imgs, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42\n    )\n    \n    print(f\"Split: {len(train_imgs)} training, {len(val_imgs)} validation, {len(test_imgs)} test images\")\n    \n    # Create TF datasets\n    num_classes = len(set(all_labels))\n    train_ds = create_tpu_dataset(train_imgs, train_labels, num_classes, is_training=True)\n    val_ds = create_tpu_dataset(val_imgs, val_labels, num_classes, is_training=False)\n    test_ds = create_tpu_dataset(test_imgs, test_labels, num_classes, is_training=False)\n    \n    return train_ds, val_ds, test_ds, num_classes, len(train_imgs), len(val_imgs)\n\ndef decode_img(file_path):\n    \"\"\"Decode an image file to a tensor\"\"\"\n    img = tf.io.read_file(file_path)\n    # Detect the image format\n    img = tf.image.decode_image(img, channels=3, expand_animations=False)\n    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n    img = tf.cast(img, tf.float32) / 255.0  # Normalize to [0,1]\n    return img\n\ndef create_tpu_dataset(image_paths, labels, num_classes, is_training=True):\n    \"\"\"Create a TPU-optimized dataset from file paths and labels\"\"\"\n    # Convert Python lists to TensorFlow tensors\n    paths_ds = tf.data.Dataset.from_tensor_slices(image_paths)\n    labels_ds = tf.data.Dataset.from_tensor_slices(labels)\n    \n    # Create a dataset of (path, label) pairs\n    dataset = tf.data.Dataset.zip((paths_ds, labels_ds))\n    \n    # Shuffle if training\n    if is_training:\n        dataset = dataset.shuffle(buffer_size=min(10000, len(image_paths)))\n        \n    # Map function to process each item\n    def process_path(file_path, label):\n        img = decode_img(file_path)\n        \n        # Data augmentation for training\n        if is_training:\n            img = tf.image.random_flip_left_right(img)\n            img = tf.image.random_brightness(img, 0.2)\n            img = tf.image.random_contrast(img, 0.8, 1.2)\n        \n        # Apply MobileNetV2 preprocessing\n        img = tf.keras.applications.mobilenet_v2.preprocess_input(img * 255.0)\n        \n        # One-hot encode the label\n        label = tf.one_hot(label, depth=num_classes)\n        return img, label\n        \n    # Apply processing function to each item\n    dataset = dataset.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n    \n    # Batch the data\n    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)  # Important for TPU: drop_remainder=True\n    \n    # Use caching for better performance\n    dataset = dataset.cache()\n    \n    # Prefetch for better performance\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    \n    return dataset\n\n# ---- 8. Prepare Datasets ----\ntry:\n    print(\"\\nPreparing datasets...\")\n    train_ds, val_ds, test_ds, num_classes, train_size, val_size = prepare_datasets()\n    \n    # Calculate steps\n    steps_per_epoch = train_size // BATCH_SIZE\n    validation_steps = val_size // BATCH_SIZE\n    \n    # Ensure at least one step\n    steps_per_epoch = max(1, steps_per_epoch)\n    validation_steps = max(1, validation_steps)\n    \n    print(f\"Dataset prepared successfully:\")\n    print(f\"Number of classes: {num_classes}\")\n    print(f\"Steps per epoch: {steps_per_epoch}\")\n    print(f\"Validation steps: {validation_steps}\")\n    \nexcept Exception as e:\n    print(f\"Error preparing datasets: {e}\")\n    # Try again with a more aggressive search\n    try:\n        print(\"\\nAttempting to find any images in the dataset...\")\n        all_image_paths = []\n        for ext in ['jpg', 'jpeg', 'png', 'JPG', 'JPEG', 'PNG']:\n            found = glob.glob(os.path.join(DATASET_PATH, \"**\", f\"*.{ext}\"), recursive=True)\n            all_image_paths.extend(found)\n            print(f\"Found {len(found)} .{ext} files\")\n        \n        if not all_image_paths:\n            raise Exception(\"No image files found in the dataset\")\n            \n        print(f\"Total images found: {len(all_image_paths)}\")\n        print(\"Sample paths:\")\n        for path in all_image_paths[:5]:\n            print(f\"  {path}\")\n            \n        raise Exception(\"Dataset structure not compatible with automatic detection. Please check paths.\")\n    except Exception as e2:\n        print(f\"Final error: {e2}\")\n        raise\n\n# ---- 9. Model Creation ----\ndef create_model():\n    \"\"\"Create the MobileNetV2 model for fruit classification\"\"\"\n    # Use smaller input size and alpha parameter for faster inference\n    base_model = MobileNetV2(\n        weights=\"imagenet\", \n        include_top=False, \n        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n        alpha=0.75  # Smaller network (75% of filters)\n    )\n\n    # Freeze base model for initial training\n    base_model.trainable = False\n\n    # Efficient Model Head\n    x = base_model.output\n    x = GlobalAveragePooling2D(name=\"gap\")(x)\n    x = Dense(128, activation=\"relu\", name=\"dense_1\")(x)\n    x = Dropout(0.4, name=\"dropout_1\")(x)\n    # Force float32 output for TPU compatibility\n    output_layer = Dense(num_classes, activation=\"softmax\", dtype='float32', name=\"output\")(x)\n\n    model = Model(inputs=base_model.input, outputs=output_layer)\n    \n    # Learning rate schedule for better convergence\n    initial_learning_rate = 0.001\n    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n        initial_learning_rate,\n        decay_steps=steps_per_epoch*2,\n        decay_rate=0.9,\n        staircase=True\n    )\n\n    # Compilation\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\", tf.keras.metrics.TopKCategoricalAccuracy(k=3, name=\"top3_acc\")]\n    )\n    \n    return model, base_model\n\n# Create model inside TPU/GPU strategy scope\nwith strategy.scope():\n    model, base_model = create_model()\n\n# Model summary\nprint(\"\\nModel Architecture Summary:\")\nmodel.summary()\n\n# ---- 10. Training Callbacks ----\ncallbacks = [\n    # Save model checkpoints\n    ModelCheckpoint(\n        filepath=CHECKPOINT_PATH,\n        monitor='val_accuracy',\n        save_best_only=True,\n        mode='max'\n    ),\n    # Early stopping to prevent overfitting\n    EarlyStopping(\n        monitor='val_loss',\n        patience=5,\n        restore_best_weights=True\n    ),\n    # Reduce learning rate when training plateaus\n    ReduceLROnPlateau(\n        monitor='val_loss', \n        factor=0.2, \n        patience=2, \n        min_lr=1e-6\n    )\n]\n\n# ---- 11. Initial TPU Compatibility Test ----\nprint(\"\\nRunning a minimal test to check hardware compatibility...\")\ntry:\n    # Take just one batch and run for one epoch as a test\n    test_train_ds = train_ds.take(1).repeat(1)\n    test_val_ds = val_ds.take(1).repeat(1)\n    \n    test_history = model.fit(\n        test_train_ds,\n        epochs=1,\n        steps_per_epoch=1,\n        validation_data=test_val_ds,\n        validation_steps=1\n    )\n    \n    print(\"Hardware compatibility test successful!\")\nexcept Exception as e:\n    print(f\"Hardware test failed: {e}\")\n    print(\"Trying alternate configuration...\")\n    \n    # Try re-initializing with different settings\n    try:\n        if 'tpu' in locals():\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            \n        # Recreate model with simpler configuration\n        with strategy.scope():\n            model = tf.keras.Sequential([\n                tf.keras.applications.MobileNetV2(\n                    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n                    include_top=False,\n                    weights='imagenet',\n                    pooling='avg'\n                ),\n                tf.keras.layers.Dense(num_classes, activation='softmax', dtype='float32')\n            ])\n            \n            model.compile(\n                optimizer='adam',\n                loss='categorical_crossentropy',\n                metrics=['accuracy']\n            )\n            \n            # Try test again\n            test_train_ds = train_ds.take(1).repeat(1)\n            test_history = model.fit(\n                test_train_ds,\n                epochs=1,\n                steps_per_epoch=1\n            )\n            \n            print(\"Alternate model configuration successful!\")\n    except Exception as e2:\n        print(f\"Alternate configuration also failed: {e2}\")\n        print(\"Falling back to CPU training with smaller batches...\")\n        \n        # Reduce batch size for CPU training\n        global BATCH_SIZE\n        original_batch_size = BATCH_SIZE\n        BATCH_SIZE = 32\n        print(f\"Reduced batch size from {original_batch_size} to {BATCH_SIZE}\")\n        \n        # Recreate datasets with smaller batch size\n        train_ds, val_ds, test_ds, _, _, _ = prepare_datasets()\n        \n        # Recreate model\n        strategy = tf.distribute.get_strategy()\n        with strategy.scope():\n            model, base_model = create_model()\n\n# ---- 12. Training Phase 1 ----\nprint(\"\\nStarting initial training phase (base model frozen)...\")\ntry:\n    history = model.fit(\n        train_ds,\n        epochs=10,  # Start with 10 epochs\n        validation_data=val_ds,\n        callbacks=callbacks,\n        steps_per_epoch=steps_per_epoch,\n        validation_steps=validation_steps\n    )\n    \n    print(\"Initial training phase completed successfully!\")\nexcept Exception as e:\n    print(f\"Error during initial training: {e}\")\n    # Try again with simpler approach\n    try:\n        print(\"Attempting simplified training...\")\n        history = model.fit(\n            train_ds,\n            epochs=5,\n            validation_data=val_ds,\n            callbacks=[],  # No callbacks to simplify\n            steps_per_epoch=min(steps_per_epoch, 10),  # Limit steps\n            validation_steps=min(validation_steps, 5)   # Limit validation steps\n        )\n    except Exception as e2:\n        print(f\"Simplified training also failed: {e2}\")\n        raise Exception(\"Training failed. Please check hardware and dataset.\")\n\n# ---- 13. Fine-tuning Phase ----\nprint(\"\\nStarting fine-tuning phase (unfreeze top layers)...\")\ntry:\n    # Unfreeze the base model (partially)\n    with strategy.scope():\n        # Unfreeze the last block of the MobileNetV2 model\n        for layer in base_model.layers[-12:]:\n            layer.trainable = True\n\n        # Count trainable parameters\n        trainable_count = sum(tf.keras.backend.count_params(w) for w in model.trainable_weights)\n        non_trainable_count = sum(tf.keras.backend.count_params(w) for w in model.non_trainable_weights)\n        print(f\"Trainable parameters: {trainable_count:,}\")\n        print(f\"Non-trainable parameters: {non_trainable_count:,}\")\n\n        # Use a much smaller learning rate for fine-tuning\n        model.compile(\n            optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n            loss=\"categorical_crossentropy\",\n            metrics=[\"accuracy\", tf.keras.metrics.TopKCategoricalAccuracy(k=3, name=\"top3_acc\")]\n        )\n\n    # Fine-tune\n    history_finetune = model.fit(\n        train_ds,\n        epochs=5,\n        validation_data=val_ds,\n        callbacks=callbacks,\n        steps_per_epoch=steps_per_epoch,\n        validation_steps=validation_steps\n    )\n    \n    print(\"Fine-tuning phase completed successfully!\")\nexcept Exception as e:\n    print(f\"Error during fine-tuning: {e}\")\n    print(\"Skipping fine-tuning phase.\")\n    history_finetune = None\n\n# ---- 14. Evaluation ----\nprint(\"\\nEvaluating model on test dataset...\")\ntry:\n    test_results = model.evaluate(test_ds)\n    print(f\"Test loss: {test_results[0]:.4f}\")\n    print(f\"Test accuracy: {test_results[1]:.4f}\")\n    if len(test_results) > 2:\n        print(f\"Test top-3 accuracy: {test_results[2]:.4f}\")\nexcept Exception as e:\n    print(f\"Error during evaluation: {e}\")\n\n# ---- 15. Save Model ----\nprint(\"\\nSaving model...\")\ntry:\n    model.save(MODEL_PATH)\n    print(f\"Saved Keras model to {MODEL_PATH}\")\n\n    # Convert to TensorFlow Lite for deployment\n    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n    tflite_model = converter.convert()\n\n    # Save the TF Lite model\n    tflite_path = os.path.join(os.path.dirname(MODEL_PATH), 'model.tflite')\n    with open(tflite_path, 'wb') as f:\n        f.write(tflite_model)\n    print(f\"Saved TFLite model to {tflite_path}\")\n    \n    # Save class indices for inference\n    class_indices = {}\n    if 'class_to_idx' in locals():\n        class_indices = {cls: idx for cls, idx in class_to_idx.items()}\n    \n    # Save to file\n    import json\n    with open('class_indices.json', 'w') as f:\n        json.dump(class_indices, f)\n    print(\"Saved class indices to class_indices.json\")\n    \nexcept Exception as e:\n    print(f\"Error saving model: {e}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T20:03:05.813885Z","iopub.execute_input":"2025-03-20T20:03:05.814265Z","iopub.status.idle":"2025-03-20T20:09:14.081309Z","shell.execute_reply.started":"2025-03-20T20:03:05.814238Z","shell.execute_reply":"2025-03-20T20:09:14.080321Z"}},"outputs":[],"execution_count":null}]}